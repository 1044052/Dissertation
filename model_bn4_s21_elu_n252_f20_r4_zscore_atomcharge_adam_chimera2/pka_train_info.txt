train: [epoch 0] loss: 5.44031654606841      test: [epoch 0] loss: 4.4585413337917394          train: [epoch 1] loss: 2.8362938713960655    test: [epoch 1] loss: 1.6605821373369167          train: [epoch 2] loss: 1.5762461000350723    test: [epoch 2] loss: 0.7817099011426494          train: [epoch 3] loss: 1.403284587973534     test: [epoch 3] loss: 0.73135628177493            train: [epoch 4] loss: 1.2957130251327782    test: [epoch 4] loss: 0.7518708978006667          train: [epoch 5] loss: 1.2121888819295041    test: [epoch 5] loss: 0.6755779315621178          train: [epoch 6] loss: 1.1476725355551398    test: [epoch 6] loss: 0.6762918013242984          train: [epoch 7] loss: 1.1044074750856123    test: [epoch 7] loss: 0.7347675219646161          train: [epoch 8] loss: 1.0801785757035842    test: [epoch 8] loss: 0.9905541384982579          train: [epoch 9] loss: 1.0737626251486798    test: [epoch 9] loss: 0.6603992243460449          train: [epoch 10] loss: 1.016677930448372    test: [epoch 10] loss: 0.7091939011052322         train: [epoch 11] loss: 1.0108169664695967   test: [epoch 11] loss: 0.6630333992427584         train: [epoch 12] loss: 0.9960158127802584   test: [epoch 12] loss: 0.8085194813359535         train: [epoch 13] loss: 0.9710094248314526   test: [epoch 13] loss: 0.7639758562496534         train: [epoch 14] loss: 0.9511291421198271   test: [epoch 14] loss: 0.649562209318741          train: [epoch 15] loss: 0.9451871992590795   test: [epoch 15] loss: 0.6388294354796028         train: [epoch 16] loss: 0.9281063763444871   test: [epoch 16] loss: 0.6793821430862056         train: [epoch 17] loss: 0.9014433989439878   test: [epoch 17] loss: 0.6328317749540057         train: [epoch 18] loss: 0.9337920173873933   test: [epoch 18] loss: 0.6419056761043036         train: [epoch 19] loss: 0.8949050164241199   test: [epoch 19] loss: 0.6205824956165438         train: [epoch 20] loss: 0.8923511842308004   test: [epoch 20] loss: 0.7563110053270946         train: [epoch 21] loss: 0.8719873142361422   test: [epoch 21] loss: 0.6009350721002705         train: [epoch 22] loss: 0.8712478303572949   test: [epoch 22] loss: 0.5992568001588012         train: [epoch 23] loss: 0.874239867769506    test: [epoch 23] loss: 0.6354741899928573         train: [epoch 24] loss: 0.8686957788981978   test: [epoch 24] loss: 0.6196743557893403         train: [epoch 25] loss: 0.8728165156558798   test: [epoch 25] loss: 0.7504285977247479         train: [epoch 26] loss: 0.8590101841989033   test: [epoch 26] loss: 0.6802639696574772         train: [epoch 27] loss: 0.8368232139310876   test: [epoch 27] loss: 0.6238405313712657         train: [epoch 28] loss: 0.8406556200878076   test: [epoch 28] loss: 0.6214014259269643         train: [epoch 29] loss: 0.8436385878866998   test: [epoch 29] loss: 0.661285224801544          train: [epoch 30] loss: 0.8303688546631565   test: [epoch 30] loss: 0.6275251751555633         train: [epoch 31] loss: 0.8214951059993627   test: [epoch 31] loss: 0.6150347969183982         train: [epoch 32] loss: 0.8140758232845827   test: [epoch 32] loss: 0.7314263164043389         train: [epoch 33] loss: 0.8288557877481136   test: [epoch 33] loss: 0.8987689375317209         train: [epoch 34] loss: 0.816468942118638    test: [epoch 34] loss: 0.5783697000134704         train: [epoch 35] loss: 0.8062146587670536   test: [epoch 35] loss: 0.6232731455769516         train: [epoch 36] loss: 0.8030151799221799   test: [epoch 36] loss: 0.5765486479176014         train: [epoch 37] loss: 0.8017483138958621   test: [epoch 37] loss: 0.6679546694866814         train: [epoch 38] loss: 0.8019490678848589   test: [epoch 38] loss: 0.7880172967242343         train: [epoch 39] loss: 0.784850806773199    test: [epoch 39] loss: 0.6028684749052623         train: [epoch 40] loss: 0.7893601524648011   test: [epoch 40] loss: 0.6490529119827135         train: [epoch 41] loss: 0.7991281902987102   test: [epoch 41] loss: 0.6597336681241068         train: [epoch 42] loss: 0.7923173639550009   test: [epoch 42] loss: 0.5792415193797985         train: [epoch 43] loss: 0.7794077724099294   test: [epoch 43] loss: 0.619147360760617          train: [epoch 44] loss: 0.7752596339467935   test: [epoch 44] loss: 0.5767735381418511         train: [epoch 45] loss: 0.7733258903907968   test: [epoch 45] loss: 0.6132997501504057         train: [epoch 46] loss: 0.772266348901928    test: [epoch 46] loss: 0.5848749318979354         train: [epoch 47] loss: 0.7689166972528975   test: [epoch 47] loss: 0.5850171898251154         train: [epoch 48] loss: 0.7617041425912343   test: [epoch 48] loss: 0.6051973206240769         train: [epoch 49] loss: 0.7643459950942918   test: [epoch 49] loss: 0.7309973647291442         train: [epoch 50] loss: 0.7743673221405101   test: [epoch 50] loss: 0.7382579769881454         train: [epoch 51] loss: 0.7448641439052835   test: [epoch 51] loss: 0.5876241307871183         train: [epoch 52] loss: 0.7535405666581717   test: [epoch 52] loss: 0.7049485935601616         train: [epoch 53] loss: 0.7547481689906462   test: [epoch 53] loss: 0.8641276576635578         train: [epoch 54] loss: 0.7633735192874938   test: [epoch 54] loss: 0.8024323891053482         train: [epoch 55] loss: 0.7607493073124844   test: [epoch 55] loss: 0.7721259263613497         train: [epoch 56] loss: 0.7510274576178825   test: [epoch 56] loss: 0.5632758508405126         train: [epoch 57] loss: 0.7415934633495269   test: [epoch 57] loss: 0.5746107380476061         train: [epoch 58] loss: 0.7572782920172647   test: [epoch 58] loss: 0.6153711110722425         train: [epoch 59] loss: 0.7592738455621789   test: [epoch 59] loss: 0.5611568155826573         train: [epoch 60] loss: 0.745884580525894    test: [epoch 60] loss: 0.5649921494488738         train: [epoch 61] loss: 0.7489051959159013   test: [epoch 61] loss: 0.5601807546201194         train: [epoch 62] loss: 0.7542449138156442   test: [epoch 62] loss: 0.6073279441588643         train: [epoch 63] loss: 0.7356373096891976   test: [epoch 63] loss: 0.549617303849992          train: [epoch 64] loss: 0.7237914782853494   test: [epoch 64] loss: 0.5520086600081376         train: [epoch 65] loss: 0.7504171228596856   test: [epoch 65] loss: 0.5888035780467898         train: [epoch 66] loss: 0.7321898599299684   test: [epoch 66] loss: 0.6301335795572244         train: [epoch 67] loss: 0.7521714753790039   test: [epoch 67] loss: 0.7562555433311797         train: [epoch 68] loss: 0.7288472539391603   test: [epoch 68] loss: 0.6382275427709343         train: [epoch 69] loss: 0.7444594131667477   test: [epoch 69] loss: 0.5808358810791786         train: [epoch 70] loss: 0.7300221743140692   test: [epoch 70] loss: 0.6711184175599784         train: [epoch 71] loss: 0.7262714074914263   test: [epoch 71] loss: 0.6360936363628975         train: [epoch 72] loss: 0.7194396813134307   test: [epoch 72] loss: 0.5398267193657534         train: [epoch 73] loss: 0.735151613229296    test: [epoch 73] loss: 0.5554870108331236         train: [epoch 74] loss: 0.7181998189703376   test: [epoch 74] loss: 0.5474423888574335         train: [epoch 75] loss: 0.7225819246455345   test: [epoch 75] loss: 0.54155737122547           train: [epoch 76] loss: 0.7386852936245163   test: [epoch 76] loss: 0.5910632624286857         train: [epoch 77] loss: 0.719050129311748    test: [epoch 77] loss: 0.5821206154901805         train: [epoch 78] loss: 0.705429893653779    test: [epoch 78] loss: 0.5362519765306534         train: [epoch 79] loss: 0.7237192279541805   test: [epoch 79] loss: 0.566264604726663          train: [epoch 80] loss: 0.7168952847990252   test: [epoch 80] loss: 0.5562850704920721         train: [epoch 81] loss: 0.7163547358345558   test: [epoch 81] loss: 0.5951067410839149         train: [epoch 82] loss: 0.7150659174733565   test: [epoch 82] loss: 0.5731542471789834         train: [epoch 83] loss: 0.7208438527147008   test: [epoch 83] loss: 0.5660076670598325         train: [epoch 84] loss: 0.7150870485198981   test: [epoch 84] loss: 0.5678111238429883         train: [epoch 85] loss: 0.7339684076579316   test: [epoch 85] loss: 0.6936001425363816         train: [epoch 86] loss: 0.7099833865535644   test: [epoch 86] loss: 0.5894947893943188         train: [epoch 87] loss: 0.7106295576806267   test: [epoch 87] loss: 0.5959363863905183         train: [epoch 88] loss: 0.7037987126834889   test: [epoch 88] loss: 0.5825581519365287         train: [epoch 89] loss: 0.7082332953090389   test: [epoch 89] loss: 0.5923911341702116         train: [epoch 90] loss: 0.7176128130591821   test: [epoch 90] loss: 0.5651115236749509         train: [epoch 91] loss: 0.711647510571975    test: [epoch 91] loss: 0.5469349578451029         train: [epoch 92] loss: 0.7040669948529652   test: [epoch 92] loss: 0.764606912854878          train: [epoch 93] loss: 0.7177450253177782   test: [epoch 93] loss: 0.6339638353176619         train: [epoch 94] loss: 0.7158049418398242   test: [epoch 94] loss: 0.5879742340256419         train: [epoch 95] loss: 0.7024206389183411   test: [epoch 95] loss: 0.6579829842135685         train: [epoch 96] loss: 0.704214567790901    test: [epoch 96] loss: 0.632620310316529          train: [epoch 97] loss: 0.6966994608040354   test: [epoch 97] loss: 0.5684109348363297         train: [epoch 98] loss: 0.7008493233815478   test: [epoch 98] loss: 0.5346905250006906         train: [epoch 99] loss: 0.7059004909254012   test: [epoch 99] loss: 0.5489038955573335         train: [epoch 100] loss: 0.6943609435742463  test: [epoch 100] loss: 0.5716276098072309        train: [epoch 101] loss: 0.6953081391350616  test: [epoch 101] loss: 0.6926619701461681        train: [epoch 102] loss: 0.697212384744546   test: [epoch 102] loss: 0.7978229713311319        train: [epoch 103] loss: 0.6906467139745824  test: [epoch 103] loss: 0.6084387742696509        train: [epoch 104] loss: 0.7082862301119984  test: [epoch 104] loss: 0.5486046746925956        train: [epoch 105] loss: 0.706936317548869   test: [epoch 105] loss: 0.5918293611611526        train: [epoch 106] loss: 0.7050753240507306  test: [epoch 106] loss: 0.630510172734385         train: [epoch 107] loss: 0.6838255090422107  test: [epoch 107] loss: 0.6535644111428607        train: [epoch 108] loss: 0.6930144060096081  test: [epoch 108] loss: 0.5363503846638769        train: [epoch 109] loss: 0.6939748217157069  test: [epoch 109] loss: 0.610665776440998         train: [epoch 110] loss: 0.6808462487430461  test: [epoch 110] loss: 0.5355902469606324        train: [epoch 111] loss: 0.6906007611829278  test: [epoch 111] loss: 0.5612996283135376        train: [epoch 112] loss: 0.6960557495955146  test: [epoch 112] loss: 0.5457804429958703        train: [epoch 113] loss: 0.6835375933968082  test: [epoch 113] loss: 0.53901050156658          train: [epoch 114] loss: 0.6895330379122095  test: [epoch 114] loss: 0.5645657437816015        train: [epoch 115] loss: 0.6787739793485733  test: [epoch 115] loss: 0.5489231381776429        train: [epoch 116] loss: 0.6950822506076457  test: [epoch 116] loss: 0.6200323197480286        train: [epoch 117] loss: 0.673878620763722   test: [epoch 117] loss: 0.5489536494865869        train: [epoch 118] loss: 0.6667648554575608  test: [epoch 118] loss: 0.6134103446552608        train: [epoch 119] loss: 0.6897976779616264  test: [epoch 119] loss: 0.5587839408028791        train: [epoch 120] loss: 0.6806104386682902  test: [epoch 120] loss: 0.6400144679589769        train: [epoch 121] loss: 0.6744434904117962  test: [epoch 121] loss: 0.5689911481237622        train: [epoch 122] loss: 0.6654178827370382  test: [epoch 122] loss: 0.5217331094320254        train: [epoch 123] loss: 0.667060050193257   test: [epoch 123] loss: 0.5485006239678926        train: [epoch 124] loss: 0.6886960019021148  test: [epoch 124] loss: 0.6192683068015227        train: [epoch 125] loss: 0.6762256904947958  test: [epoch 125] loss: 0.5583463351218845        train: [epoch 126] loss: 0.6998038798110027  test: [epoch 126] loss: 0.7846795911701333        train: [epoch 127] loss: 0.6948857293100389  test: [epoch 127] loss: 0.580742523094157         train: [epoch 128] loss: 0.6717773139447925  test: [epoch 128] loss: 0.5296990238955788        train: [epoch 129] loss: 0.6721453040418801  test: [epoch 129] loss: 0.5856544493618748        train: [epoch 130] loss: 0.6581355022648845  test: [epoch 130] loss: 0.57261071597068          train: [epoch 131] loss: 0.673483674134301   test: [epoch 131] loss: 0.565521633741487         train: [epoch 132] loss: 0.6668721688847652  test: [epoch 132] loss: 0.6391481204236045        train: [epoch 133] loss: 0.6937326082634572  test: [epoch 133] loss: 0.6222993893961108        train: [epoch 134] loss: 0.6829565060849242  test: [epoch 134] loss: 0.5348768270874664        train: [epoch 135] loss: 0.6737569254494262  test: [epoch 135] loss: 0.600070577501286         train: [epoch 136] loss: 0.665746809373756   test: [epoch 136] loss: 0.6099544004105036        train: [epoch 137] loss: 0.6630136008633161  test: [epoch 137] loss: 0.5670116335854954        train: [epoch 138] loss: 0.663755754747895   test: [epoch 138] loss: 0.533500339745985         train: [epoch 139] loss: 0.6700752141953392  test: [epoch 139] loss: 0.5244053771875921        train: [epoch 140] loss: 0.6644403298250329  test: [epoch 140] loss: 0.5689189357941501        train: [epoch 141] loss: 0.6495749064959676  test: [epoch 141] loss: 0.5603891154104413        train: [epoch 142] loss: 0.6653907014679465  test: [epoch 142] loss: 0.5679475008174256        train: [epoch 143] loss: 0.669708930152656   test: [epoch 143] loss: 0.5629617053851274        train: [epoch 144] loss: 0.6852484142297163  test: [epoch 144] loss: 0.6405974327179488        train: [epoch 145] loss: 0.660630092094002   test: [epoch 145] loss: 0.6347036453649627        train: [epoch 146] loss: 0.6666954234037235  test: [epoch 146] loss: 0.5638572352950035        train: [epoch 147] loss: 0.6649981963251719  test: [epoch 147] loss: 0.5453180461120092        train: [epoch 148] loss: 0.6569670772464524  test: [epoch 148] loss: 0.5380241521365925        train: [epoch 149] loss: 0.6530781974720432  test: [epoch 149] loss: 0.5230461410272214        train: [epoch 150] loss: 0.648658111116631   test: [epoch 150] loss: 0.5406664647215322        train: [epoch 151] loss: 0.646962728696119   test: [epoch 151] loss: 0.5176153547146085        train: [epoch 152] loss: 0.6504835658599604  test: [epoch 152] loss: 0.759557795214745         train: [epoch 153] loss: 0.6697539103188463  test: [epoch 153] loss: 0.5308943160988289        train: [epoch 154] loss: 0.6493610606257125  test: [epoch 154] loss: 0.5757210637303622        train: [epoch 155] loss: 0.6544585845629325  test: [epoch 155] loss: 0.6036466994957058        train: [epoch 156] loss: 0.6382480293497532  test: [epoch 156] loss: 0.5486348986122364        train: [epoch 157] loss: 0.6400401108350776  test: [epoch 157] loss: 0.5813634573484324        train: [epoch 158] loss: 0.6561687458485745  test: [epoch 158] loss: 0.5382669730235339        train: [epoch 159] loss: 0.6503772380138518  test: [epoch 159] loss: 0.5308675777728131        train: [epoch 160] loss: 0.6388222555132856  test: [epoch 160] loss: 0.5441022818402476        train: [epoch 161] loss: 0.6490388689041179  test: [epoch 161] loss: 0.6765399193435241        train: [epoch 162] loss: 0.6407941450958076  test: [epoch 162] loss: 0.5268012179313843        train: [epoch 163] loss: 0.6421371350414745  test: [epoch 163] loss: 0.5311989403830873        train: [epoch 164] loss: 0.6574089387411098  test: [epoch 164] loss: 0.521262943453965         train: [epoch 165] loss: 0.6428174179082452  test: [epoch 165] loss: 0.6200773935105152        train: [epoch 166] loss: 0.6499970359919429  test: [epoch 166] loss: 0.5343805698753133        train: [epoch 167] loss: 0.6472998335652521  test: [epoch 167] loss: 0.537802016813018         train: [epoch 168] loss: 0.6382800826553146  test: [epoch 168] loss: 0.6665840213506488        train: [epoch 169] loss: 0.6437947638644663  test: [epoch 169] loss: 0.5290909771949067        train: [epoch 170] loss: 0.6544668497111905  test: [epoch 170] loss: 0.5380825408794498        train: [epoch 171] loss: 0.6418330805050395  test: [epoch 171] loss: 0.5443888056910368        train: [epoch 172] loss: 0.6493904595295377  test: [epoch 172] loss: 0.5523553595401755        train: [epoch 173] loss: 0.6486151038325008  test: [epoch 173] loss: 0.6462932661282927        train: [epoch 174] loss: 0.6450588249308012  test: [epoch 174] loss: 0.5256962961155521        train: [epoch 175] loss: 0.6448530800513477  test: [epoch 175] loss: 0.5366992756398057        train: [epoch 176] loss: 0.6474563359936184  test: [epoch 176] loss: 0.6007712038731788        train: [epoch 177] loss: 0.6415282509294442  test: [epoch 177] loss: 0.6109228301369694        train: [epoch 178] loss: 0.6480373224133043  test: [epoch 178] loss: 0.6709941697316677        train: [epoch 179] loss: 0.6337798424406005  test: [epoch 179] loss: 0.5333505373218062        train: [epoch 180] loss: 0.6444953002304479  test: [epoch 180] loss: 0.573374642513825         train: [epoch 181] loss: 0.627357358540344   test: [epoch 181] loss: 0.635199495694586         train: [epoch 182] loss: 0.6453718513934587  test: [epoch 182] loss: 0.6119079400231838        train: [epoch 183] loss: 0.6310538777479503  test: [epoch 183] loss: 0.6212634174455683        train: [epoch 184] loss: 0.6208416106131164  test: [epoch 184] loss: 0.5472803751386913        train: [epoch 185] loss: 0.6301359868427598  test: [epoch 185] loss: 0.5372240978934651        train: [epoch 186] loss: 0.6406482844765007  test: [epoch 186] loss: 0.5411867531894887        train: [epoch 187] loss: 0.6253676432220363  test: [epoch 187] loss: 0.5693959381760011        train: [epoch 188] loss: 0.623951265719131   test: [epoch 188] loss: 0.5587172644377318        train: [epoch 189] loss: 0.6245453853625067  test: [epoch 189] loss: 0.647076732422496         train: [epoch 190] loss: 0.6369324005988342  test: [epoch 190] loss: 0.5323510508566333        train: [epoch 191] loss: 0.6337457138633589  test: [epoch 191] loss: 0.6309112857304048        train: [epoch 192] loss: 0.6117244592975134  test: [epoch 192] loss: 0.6740649462677537        train: [epoch 193] loss: 0.6422835450005785  test: [epoch 193] loss: 0.5831251052969953        train: [epoch 194] loss: 0.6250449138666226  test: [epoch 194] loss: 0.5629284435734795        train: [epoch 195] loss: 0.6323055894794828  test: [epoch 195] loss: 0.6235754292113214        train: [epoch 196] loss: 0.6228810103939838  test: [epoch 196] loss: 0.5786908002254394        train: [epoch 197] loss: 0.6199704337787124  test: [epoch 197] loss: 0.5752042931797376        train: [epoch 198] loss: 0.6250509311829064  test: [epoch 198] loss: 0.639340611474662         train: [epoch 199] loss: 0.6286229490432549  test: [epoch 199] loss: 0.5873486464189409        train: [epoch 200] loss: 0.6225913893879911  test: [epoch 200] loss: 0.6108375552090995        train: [epoch 201] loss: 0.6101325076588404  test: [epoch 201] loss: 0.5199872623176459        train: [epoch 202] loss: 0.6238095740214032  test: [epoch 202] loss: 0.5432412733097184        train: [epoch 203] loss: 0.6214647043361717  test: [epoch 203] loss: 0.5475100149394883        train: [epoch 204] loss: 0.6488323124719042  test: [epoch 204] loss: 0.5509403851424686        train: [epoch 205] loss: 0.6247744138477287  test: [epoch 205] loss: 0.5442716260051338        train: [epoch 206] loss: 0.6193794097098435  test: [epoch 206] loss: 0.673392856316514         train: [epoch 207] loss: 0.6142559701439878  test: [epoch 207] loss: 0.5926450172561024        train: [epoch 208] loss: 0.6099432537685567  test: [epoch 208] loss: 0.5420610234160501        train: [epoch 209] loss: 0.6279049398390839  test: [epoch 209] loss: 0.581115931591273         train: [epoch 210] loss: 0.6212882844813604  test: [epoch 210] loss: 0.5402687925190942        train: [epoch 211] loss: 0.6248136586346754  test: [epoch 211] loss: 0.5252125824212895        train: [epoch 212] loss: 0.6354936589657643  test: [epoch 212] loss: 0.5561977701352776        train: [epoch 213] loss: 0.625145956752545   test: [epoch 213] loss: 0.5700647351183143        train: [epoch 214] loss: 0.6018970580962906  test: [epoch 214] loss: 0.534733281255853         train: [epoch 215] loss: 0.6101410485546764  test: [epoch 215] loss: 0.5280298971570703        train: [epoch 216] loss: 0.623470637190585   test: [epoch 216] loss: 0.5653302794980953        train: [epoch 217] loss: 0.6078672147783901  test: [epoch 217] loss: 0.534652702866228         train: [epoch 218] loss: 0.6031143343789848  test: [epoch 218] loss: 0.5321538722925181        train: [epoch 219] loss: 0.6028306728896868  test: [epoch 219] loss: 0.5315161413933859        train: [epoch 220] loss: 0.6076756284028946  test: [epoch 220] loss: 0.5334783476785232        train: [epoch 221] loss: 0.6256787244353049  test: [epoch 221] loss: 0.5666822836835608        train: [epoch 222] loss: 0.6258221485510961  test: [epoch 222] loss: 0.5507382481041476        train: [epoch 223] loss: 0.6139090330811393  test: [epoch 223] loss: 0.5427977315355559        train: [epoch 224] loss: 0.6076879776520355  test: [epoch 224] loss: 0.5458704476554186        train: [epoch 225] loss: 0.6098179301514224  test: [epoch 225] loss: 0.5439359429659996        train: [epoch 226] loss: 0.5999529703507254  test: [epoch 226] loss: 0.5430091201254684        train: [epoch 227] loss: 0.6020012626780692  test: [epoch 227] loss: 0.5400563350630115        train: [epoch 228] loss: 0.6119677148728812  test: [epoch 228] loss: 0.5774250615398938        train: [epoch 229] loss: 0.615780930541295   test: [epoch 229] loss: 0.5472585644337519        train: [epoch 230] loss: 0.618870483088808   test: [epoch 230] loss: 0.5411805362721305        train: [epoch 231] loss: 0.599343902092446   test: [epoch 231] loss: 0.5554674397524775        train: [epoch 232] loss: 0.5997959467583892  test: [epoch 232] loss: 0.8213429479088593        train: [epoch 233] loss: 0.5890894276292511  test: [epoch 233] loss: 0.5664676435866484        train: [epoch 234] loss: 0.6025572837508782  test: [epoch 234] loss: 0.5181565392264544        train: [epoch 235] loss: 0.6027991027083702  test: [epoch 235] loss: 0.6504081434390755        train: [epoch 236] loss: 0.5899006085164318  test: [epoch 236] loss: 0.5586153708319634        train: [epoch 237] loss: 0.5942097009647833  test: [epoch 237] loss: 0.5365141195157042        train: [epoch 238] loss: 0.600093124997614   test: [epoch 238] loss: 0.5969780918506883        train: [epoch 239] loss: 0.5883079972527863  test: [epoch 239] loss: 0.6414567051556792        train: [epoch 240] loss: 0.599595715200043   test: [epoch 240] loss: 0.535679511496687         train: [epoch 241] loss: 0.6200049578753979  test: [epoch 241] loss: 0.5694129026162986        train: [epoch 242] loss: 0.6006307465589212  test: [epoch 242] loss: 0.5623017989714908        train: [epoch 243] loss: 0.5835614078274503  test: [epoch 243] loss: 0.5242684616587254        train: [epoch 244] loss: 0.6107627841116426  test: [epoch 244] loss: 0.5119371198582996        train: [epoch 245] loss: 0.5938441939699306  test: [epoch 245] loss: 0.5306806284712299        train: [epoch 246] loss: 0.5877076489118942  test: [epoch 246] loss: 0.6467754467176718        train: [epoch 247] loss: 0.5895932544485702  test: [epoch 247] loss: 0.6269989877049449        train: [epoch 248] loss: 0.602978727198933   test: [epoch 248] loss: 0.5429006597124796        train: [epoch 249] loss: 0.5908144546292762  test: [epoch 249] loss: 0.5721992099190816        train: [epoch 250] loss: 0.5720534408095375  test: [epoch 250] loss: 0.5502442798003194        train: [epoch 251] loss: 0.5899368849050829  test: [epoch 251] loss: 0.6093672706131116        train: [epoch 252] loss: 0.5889286958649814  test: [epoch 252] loss: 0.5464101932400762        train: [epoch 253] loss: 0.5886842335367357  test: [epoch 253] loss: 0.5396398591577328        train: [epoch 254] loss: 0.5851437702984695  test: [epoch 254] loss: 0.5921739275296727        train: [epoch 255] loss: 0.5935597999760304  test: [epoch 255] loss: 0.5294719578986204        train: [epoch 256] loss: 0.59483340644377    test: [epoch 256] loss: 0.5371889127796983        train: [epoch 257] loss: 0.5853254852902036  test: [epoch 257] loss: 0.5437215268048602        train: [epoch 258] loss: 0.5829486533570325  test: [epoch 258] loss: 0.5760402996172304        train: [epoch 259] loss: 0.6001308942355473  test: [epoch 259] loss: 0.555155526720184         train: [epoch 260] loss: 0.6043744050145289  test: [epoch 260] loss: 0.5495681636947384        train: [epoch 261] loss: 0.5906981127859012  test: [epoch 261] loss: 0.5665119456305091        train: [epoch 262] loss: 0.594673329366382   test: [epoch 262] loss: 0.5423199502753709        train: [epoch 263] loss: 0.5821033873561474  test: [epoch 263] loss: 0.5553809821956308        train: [epoch 264] loss: 0.5833604783673441  test: [epoch 264] loss: 0.6431528661840437        train: [epoch 265] loss: 0.5656183202260615  test: [epoch 265] loss: 0.5155116364347476        train: [epoch 266] loss: 0.6086093275292103  test: [epoch 266] loss: 0.5704351383445236        train: [epoch 267] loss: 0.5899777760943545  test: [epoch 267] loss: 0.5475800202650828        train: [epoch 268] loss: 0.5930856868453368  test: [epoch 268] loss: 0.538582781875618         train: [epoch 269] loss: 0.5784277405978452  test: [epoch 269] loss: 0.591049040533312         train: [epoch 270] loss: 0.5696394156391063  test: [epoch 270] loss: 0.5711230126685555        train: [epoch 271] loss: 0.5740815477330924  test: [epoch 271] loss: 0.632128844627139         train: [epoch 272] loss: 0.5848181437206723  test: [epoch 272] loss: 0.5317104247978293        train: [epoch 273] loss: 0.585831759971597   test: [epoch 273] loss: 0.5421938999225069        train: [epoch 274] loss: 0.588695037279005   test: [epoch 274] loss: 0.5616983499385848        train: [epoch 275] loss: 0.5857731312798992  test: [epoch 275] loss: 0.5351030212537022        train: [epoch 276] loss: 0.579181425875617   test: [epoch 276] loss: 0.5610398031725992        train: [epoch 277] loss: 0.5593153364024593  test: [epoch 277] loss: 0.5561534679344443        train: [epoch 278] loss: 0.6005691740052579  test: [epoch 278] loss: 0.5306517889194329        train: [epoch 279] loss: 0.594475562354509   test: [epoch 279] loss: 0.5342427979230965        train: [epoch 280] loss: 0.55846212731167    test: [epoch 280] loss: 0.539677406741457         train: [epoch 281] loss: 0.577520950878679   test: [epoch 281] loss: 0.5502089253849602        train: [epoch 282] loss: 0.5772001942144865  test: [epoch 282] loss: 0.5482901430376926        train: [epoch 283] loss: 0.5790976527139152  test: [epoch 283] loss: 0.5428884469962706        train: [epoch 284] loss: 0.5829440054617869  test: [epoch 284] loss: 0.7404277594653155        train: [epoch 285] loss: 0.5759038087867726  test: [epoch 285] loss: 0.5632285468078533        train: [epoch 286] loss: 0.5728267103931128  test: [epoch 286] loss: 0.5263010402893478        train: [epoch 287] loss: 0.5621790139006355  test: [epoch 287] loss: 0.5651898635696423        train: [epoch 288] loss: 0.5528947652468758  test: [epoch 288] loss: 0.5316981438285115        train: [epoch 289] loss: 0.5686657924278196  test: [epoch 289] loss: 0.5753650424539191        train: [epoch 290] loss: 0.572149984722942   test: [epoch 290] loss: 0.5459908825249989        train: [epoch 291] loss: 0.5684506772331118  test: [epoch 291] loss: 0.611417208076597         train: [epoch 292] loss: 0.5668071160619775  test: [epoch 292] loss: 0.6078406066136076        train: [epoch 293] loss: 0.5527795815751602  test: [epoch 293] loss: 0.6651208262370596        train: [epoch 294] loss: 0.5657674927703329  test: [epoch 294] loss: 0.5465398175148714        train: [epoch 295] loss: 0.575258309053272   test: [epoch 295] loss: 0.5606976164626708        train: [epoch 296] loss: 0.5569941131528254  test: [epoch 296] loss: 0.5564387007659766        train: [epoch 297] loss: 0.557726374247873   test: [epoch 297] loss: 0.5933155246554247        train: [epoch 298] loss: 0.5756813872858778  test: [epoch 298] loss: 0.5523706270101365        train: [epoch 299] loss: 0.5642468511235265  test: [epoch 299] loss: 0.6437876371443776        train: [epoch 300] loss: 0.5643128832002887  test: [epoch 300] loss: 0.5427053073784108        train: [epoch 301] loss: 0.5630440728003697  test: [epoch 301] loss: 0.5581048365853027        train: [epoch 302] loss: 0.5535944738658487  test: [epoch 302] loss: 0.5442962617057702        train: [epoch 303] loss: 0.5725523705106814  test: [epoch 303] loss: 0.5280316569478001        train: [epoch 304] loss: 0.5590050412313484  test: [epoch 304] loss: 0.5578978322393825        train: [epoch 305] loss: 0.5711629582123015  test: [epoch 305] loss: 0.538734630903871         train: [epoch 306] loss: 0.5592370340796625  test: [epoch 306] loss: 0.5340820547741323        train: [epoch 307] loss: 0.5444559157615131  test: [epoch 307] loss: 0.532725140937397         train: [epoch 308] loss: 0.5422909926579155  test: [epoch 308] loss: 0.5311604821187496        train: [epoch 309] loss: 0.5491174204720627  test: [epoch 309] loss: 0.547280455409013         train: [epoch 310] loss: 0.5444363806228658  test: [epoch 310] loss: 0.5412921512178513        train: [epoch 311] loss: 0.573790494120353   test: [epoch 311] loss: 0.5441061058297344        train: [epoch 312] loss: 0.5711694925056923  test: [epoch 312] loss: 0.5495951782763949        train: [epoch 313] loss: 0.5402160395692942  test: [epoch 313] loss: 0.5389270340200368        train: [epoch 314] loss: 0.5493066765062858  test: [epoch 314] loss: 0.5318245953531227        train: [epoch 315] loss: 0.5513356857259185  test: [epoch 315] loss: 0.5582227744225623        train: [epoch 316] loss: 0.5455163881708821  test: [epoch 316] loss: 0.5425686254086408        train: [epoch 317] loss: 0.5498654728055155  test: [epoch 317] loss: 0.5441281992256248        train: [epoch 318] loss: 0.5579156148500218  test: [epoch 318] loss: 0.5388635290093291        train: [epoch 319] loss: 0.5576400040887138  test: [epoch 319] loss: 0.5372713174111522        train: [epoch 320] loss: 0.5488425776511139  test: [epoch 320] loss: 0.525905570658599         train: [epoch 321] loss: 0.5537380914556254  test: [epoch 321] loss: 0.5846224486518022        train: [epoch 322] loss: 0.5392755662930457  test: [epoch 322] loss: 0.5579274777161201        train: [epoch 323] loss: 0.5667733957599536  test: [epoch 323] loss: 0.5261775461080104        train: [epoch 324] loss: 0.5576126257377021  test: [epoch 324] loss: 0.5559828808077579        train: [epoch 325] loss: 0.5343205872159497  test: [epoch 325] loss: 0.5200004015224093        train: [epoch 326] loss: 0.532816603043819   test: [epoch 326] loss: 0.5426122395379143        train: [epoch 327] loss: 0.5294953348259467  test: [epoch 327] loss: 0.5440595896266585        train: [epoch 328] loss: 0.5357833249945039  test: [epoch 328] loss: 0.5683766256587377        train: [epoch 329] loss: 0.5433715183257462  test: [epoch 329] loss: 0.5433135297107899        train: [epoch 330] loss: 0.5355516571760734  test: [epoch 330] loss: 0.548482751206457         train: [epoch 331] loss: 0.5358402694566343  test: [epoch 331] loss: 0.5626921810745605        train: [epoch 332] loss: 0.5644910284004295  test: [epoch 332] loss: 0.5559585568324567        train: [epoch 333] loss: 0.5470594867500792  test: [epoch 333] loss: 0.5687257480813902        train: [epoch 334] loss: 0.5503815185098322  test: [epoch 334] loss: 0.5250314609141844        train: [epoch 335] loss: 0.5365821181413596  test: [epoch 335] loss: 0.5714782297775286        train: [epoch 336] loss: 0.5399776906431636  test: [epoch 336] loss: 0.6321829645024974        train: [epoch 337] loss: 0.5307009955357177  test: [epoch 337] loss: 0.547437942797076         train: [epoch 338] loss: 0.5398619152487321  test: [epoch 338] loss: 0.5136117867092972        train: [epoch 339] loss: 0.5289038042626798  test: [epoch 339] loss: 0.5543097077429427        train: [epoch 340] loss: 0.5398234012010531  test: [epoch 340] loss: 0.5862708284847674        train: [epoch 341] loss: 0.5219599339172267  test: [epoch 341] loss: 0.5558529493765864        train: [epoch 342] loss: 0.5351275272185134  test: [epoch 342] loss: 0.5371641365340015        train: [epoch 343] loss: 0.5179187171383767  test: [epoch 343] loss: 0.5665780716401206        train: [epoch 344] loss: 0.5282539216240804  test: [epoch 344] loss: 0.5979419354002169        train: [epoch 345] loss: 0.5438503314734058  test: [epoch 345] loss: 0.5246747790250043        train: [epoch 346] loss: 0.5411457391048108  test: [epoch 346] loss: 0.6185237487473694        train: [epoch 347] loss: 0.5384215531636577  test: [epoch 347] loss: 0.5401545165211271        train: [epoch 348] loss: 0.5392211475528508  test: [epoch 348] loss: 0.5781444612753025        train: [epoch 349] loss: 0.517530954246123   test: [epoch 349] loss: 0.536276447422647         train: [epoch 350] loss: 0.5376904191904037  test: [epoch 350] loss: 0.5359456039100549        train: [epoch 351] loss: 0.5527194299790457  test: [epoch 351] loss: 0.6064636441841978        train: [epoch 352] loss: 0.52796696795279    test: [epoch 352] loss: 0.5366856495169832        train: [epoch 353] loss: 0.5154948481605971  test: [epoch 353] loss: 0.5462167823802812        train: [epoch 354] loss: 0.5399474302541226  test: [epoch 354] loss: 0.5192875453144046        train: [epoch 355] loss: 0.5288782641656005  test: [epoch 355] loss: 0.539662516315239         train: [epoch 356] loss: 0.5366027721033635  test: [epoch 356] loss: 0.5250043682869564        train: [epoch 357] loss: 0.5410191190016864  test: [epoch 357] loss: 0.573417114859259         train: [epoch 358] loss: 0.5341602509247981  test: [epoch 358] loss: 0.5225310331508471        train: [epoch 359] loss: 0.5438521089028441  test: [epoch 359] loss: 0.5380768097126541        train: [epoch 360] loss: 0.5349195558888694  test: [epoch 360] loss: 0.5172057610562301        train: [epoch 361] loss: 0.5183745930702807  test: [epoch 361] loss: 0.7023961256819934        train: [epoch 362] loss: 0.512468738458895   test: [epoch 362] loss: 0.5326696753298457        train: [epoch 363] loss: 0.5009449304550301  test: [epoch 363] loss: 0.5414046054791336        train: [epoch 364] loss: 0.4984554139644013  test: [epoch 364] loss: 0.5204514461251332        train: [epoch 365] loss: 0.5310770770078126  test: [epoch 365] loss: 0.5829044363675544        train: [epoch 366] loss: 0.5351209793506818  test: [epoch 366] loss: 0.5761166558962775        train: [epoch 367] loss: 0.5123362047767561  test: [epoch 367] loss: 0.5324706103733643        train: [epoch 368] loss: 0.5331256317249119  test: [epoch 368] loss: 0.5354170305043664        train: [epoch 369] loss: 0.5214394888618006  test: [epoch 369] loss: 0.5421178092086458        train: [epoch 370] loss: 0.519563063903899   test: [epoch 370] loss: 0.5542440722780482        train: [epoch 371] loss: 0.5213218547114569  test: [epoch 371] loss: 0.53463291864206          train: [epoch 372] loss: 0.5302266743432218  test: [epoch 372] loss: 0.5347497581130991        train: [epoch 373] loss: 0.5150438392105605  test: [epoch 373] loss: 0.5633207303388412        train: [epoch 374] loss: 0.5121760619830961  test: [epoch 374] loss: 0.5625071887800013        train: [epoch 375] loss: 0.5223153735592699  test: [epoch 375] loss: 0.5464824187751255        train: [epoch 376] loss: 0.522549949251983   test: [epoch 376] loss: 0.5389250173960535        train: [epoch 377] loss: 0.5281685959469755  test: [epoch 377] loss: 0.543231615099444         train: [epoch 378] loss: 0.5323623496274917  test: [epoch 378] loss: 0.5692657034288695        train: [epoch 379] loss: 0.5096725156463923  test: [epoch 379] loss: 0.5482200281304911        train: [epoch 380] loss: 0.5220642440808757  test: [epoch 380] loss: 0.5677446488016927        train: [epoch 381] loss: 0.5115640709920167  test: [epoch 381] loss: 0.5454098950477222        train: [epoch 382] loss: 0.5207219632927937  test: [epoch 382] loss: 0.5809305949908089        train: [epoch 383] loss: 0.5341314638313193  test: [epoch 383] loss: 0.5870995461264652        train: [epoch 384] loss: 0.5166339610537066  test: [epoch 384] loss: 0.5163258682677567        train: [epoch 385] loss: 0.49649951968942957 test: [epoch 385] loss: 0.5663943797053578        train: [epoch 386] loss: 0.5123996165640363  test: [epoch 386] loss: 0.5531849664978571        train: [epoch 387] loss: 0.5269090993714229  test: [epoch 387] loss: 0.5520813830926301        train: [epoch 388] loss: 0.517756356558998   test: [epoch 388] loss: 0.5234194867047552        train: [epoch 389] loss: 0.5289067933323436  test: [epoch 389] loss: 0.5578741531056362        train: [epoch 390] loss: 0.49988585998083185 test: [epoch 390] loss: 0.5412934643141913        train: [epoch 391] loss: 0.5255351402002028  test: [epoch 391] loss: 0.5397275906571648        train: [epoch 392] loss: 0.5027265032350049  test: [epoch 392] loss: 0.5395864117552335        train: [epoch 393] loss: 0.5061050438876256  test: [epoch 393] loss: 0.526317841504652         train: [epoch 394] loss: 0.4989894514287526  test: [epoch 394] loss: 0.6280303159996434        train: [epoch 395] loss: 0.5137574166770509  test: [epoch 395] loss: 0.5597824212882565        train: [epoch 396] loss: 0.5071091320151804  test: [epoch 396] loss: 0.574503758060013         train: [epoch 397] loss: 0.5045395095054566  test: [epoch 397] loss: 0.549651992709953         train: [epoch 398] loss: 0.49607355777894546 test: [epoch 398] loss: 0.5404019568041429        train: [epoch 399] loss: 0.5167650557586789  test: [epoch 399] loss: 0.552886730773537         train: [epoch 400] loss: 0.48971691241683096 test: [epoch 400] loss: 0.5594271410674629        train: [epoch 401] loss: 0.5010509420841909  test: [epoch 401] loss: 0.5498585516599754        train: [epoch 402] loss: 0.5253633388571413  test: [epoch 402] loss: 0.5294204548618748        train: [epoch 403] loss: 0.49271679685828407 test: [epoch 403] loss: 0.5560949417927039        train: [epoch 404] loss: 0.500957604216377   test: [epoch 404] loss: 0.5649058248934805        train: [epoch 405] loss: 0.48579750050992043 test: [epoch 405] loss: 0.5273452532438098        train: [epoch 406] loss: 0.5075507276721257  test: [epoch 406] loss: 0.5447521168785132        train: [epoch 407] loss: 0.5164843678082661  test: [epoch 407] loss: 0.5362008507965483        train: [epoch 408] loss: 0.49035486876147044 test: [epoch 408] loss: 0.5449217814217269        train: [epoch 409] loss: 0.5067415316773151  test: [epoch 409] loss: 0.5521643584461869        train: [epoch 410] loss: 0.49643034487715043 test: [epoch 410] loss: 0.6015777401045985        train: [epoch 411] loss: 0.511631258533803   test: [epoch 411] loss: 0.5298192465048241        train: [epoch 412] loss: 0.5165250603702483  test: [epoch 412] loss: 0.5801728804856809        train: [epoch 413] loss: 0.499573381373207   test: [epoch 413] loss: 0.5373358038394171        train: [epoch 414] loss: 0.5330821529600954  test: [epoch 414] loss: 0.5649552125550268        train: [epoch 415] loss: 0.5083657311825732  test: [epoch 415] loss: 0.5351021314527626        train: [epoch 416] loss: 0.49876378998740123 test: [epoch 416] loss: 0.5472328037530997        train: [epoch 417] loss: 0.5291577151575384  test: [epoch 417] loss: 0.5563585715570338        train: [epoch 418] loss: 0.5083961270258894  test: [epoch 418] loss: 0.5653649003786753        train: [epoch 419] loss: 0.5108441474277251  test: [epoch 419] loss: 0.543028074474251         train: [epoch 420] loss: 0.4765973854836617  test: [epoch 420] loss: 0.5504794797217069        train: [epoch 421] loss: 0.4841444159436486  test: [epoch 421] loss: 0.6443680245618946        train: [epoch 422] loss: 0.5037152915264469  test: [epoch 422] loss: 0.5542115412897117        train: [epoch 423] loss: 0.4783463073938953  test: [epoch 423] loss: 0.5412867571010069        train: [epoch 424] loss: 0.4829910526215911  test: [epoch 424] loss: 0.5640801123797963        train: [epoch 425] loss: 0.4857843173520213  test: [epoch 425] loss: 0.5366341889863266        train: [epoch 426] loss: 0.4895268441850304  test: [epoch 426] loss: 0.5558424348391485        train: [epoch 427] loss: 0.495553749672289   test: [epoch 427] loss: 0.5371408444432186        train: [epoch 428] loss: 0.4984840950167641  test: [epoch 428] loss: 0.5414182258055527        train: [epoch 429] loss: 0.47891081597311547 test: [epoch 429] loss: 0.5436624576620996        train: [epoch 430] loss: 0.4859188961964646  test: [epoch 430] loss: 0.5593765892359402        train: [epoch 431] loss: 0.5059095821912889  test: [epoch 431] loss: 0.5329667271419231        train: [epoch 432] loss: 0.4992985832031502  test: [epoch 432] loss: 0.5297072163812603        train: [epoch 433] loss: 0.4850275099472505  test: [epoch 433] loss: 0.5348889628038427        train: [epoch 434] loss: 0.4829032621146565  test: [epoch 434] loss: 0.5411989012874068        train: [epoch 435] loss: 0.4907358535427111  test: [epoch 435] loss: 0.5427163076488442        train: [epoch 436] loss: 0.49527621369745445 test: [epoch 436] loss: 0.5444177306219598        train: [epoch 437] loss: 0.48657085499776254 test: [epoch 437] loss: 0.6321440279585978        train: [epoch 438] loss: 0.4911435076290265  test: [epoch 438] loss: 0.5580090771421339        train: [epoch 439] loss: 0.4859146948929612  test: [epoch 439] loss: 0.5307615143566233        train: [epoch 440] loss: 0.4901195968756034  test: [epoch 440] loss: 0.5405413650281551        train: [epoch 441] loss: 0.505015230749904   test: [epoch 441] loss: 0.5350377358216565        train: [epoch 442] loss: 0.48282689027901843 test: [epoch 442] loss: 0.52758096801777          train: [epoch 443] loss: 0.4797633363616228  test: [epoch 443] loss: 0.5578800370112922        train: [epoch 444] loss: 0.47502725153024733 test: [epoch 444] loss: 0.5900582166120851        train: [epoch 445] loss: 0.48133649893716207 test: [epoch 445] loss: 0.6333509456921642        train: [epoch 446] loss: 0.4710104006495415  test: [epoch 446] loss: 0.5519788287549677        train: [epoch 447] loss: 0.4707962820313716  test: [epoch 447] loss: 0.5908443576953676        train: [epoch 448] loss: 0.4816574650094423  test: [epoch 448] loss: 0.5335495470750111        train: [epoch 449] loss: 0.4696042757817356  test: [epoch 449] loss: 0.5516224817017334        train: [epoch 450] loss: 0.47866456657474366 test: [epoch 450] loss: 0.528744436120025         train: [epoch 451] loss: 0.48931618572721797 test: [epoch 451] loss: 0.5262187419916888        train: [epoch 452] loss: 0.5020925630689519  test: [epoch 452] loss: 0.5566519351598063        train: [epoch 453] loss: 0.47452674572691905 test: [epoch 453] loss: 0.563120330196109         train: [epoch 454] loss: 0.485068183359879   test: [epoch 454] loss: 0.5407861932754852        train: [epoch 455] loss: 0.48892862742044707 test: [epoch 455] loss: 0.5427736150243246        train: [epoch 456] loss: 0.46403298225808587 test: [epoch 456] loss: 0.6245097886889175        train: [epoch 457] loss: 0.4818116032154188  test: [epoch 457] loss: 0.5387952676655985        train: [epoch 458] loss: 0.4813432428859504  test: [epoch 458] loss: 0.5474256602758791        train: [epoch 459] loss: 0.48313989780177197 test: [epoch 459] loss: 0.5799314252303532        train: [epoch 460] loss: 0.4929100285643348  test: [epoch 460] loss: 0.5380746554479865        train: [epoch 461] loss: 0.4838581228104713  test: [epoch 461] loss: 0.5711934473015711        train: [epoch 462] loss: 0.49452161048890053 test: [epoch 462] loss: 0.6149489198462268        train: [epoch 463] loss: 0.493937784164942   test: [epoch 463] loss: 0.5403678524561156        train: [epoch 464] loss: 0.47825327243164534 test: [epoch 464] loss: 0.5612866938973106        train: [epoch 465] loss: 0.46118043421013477 test: [epoch 465] loss: 0.5301807154720694        train: [epoch 466] loss: 0.47497205592224256 test: [epoch 466] loss: 0.5456151425447592        train: [epoch 467] loss: 0.493637269860512   test: [epoch 467] loss: 0.5689363556630993        train: [epoch 468] loss: 0.46340917770311685 test: [epoch 468] loss: 0.5311140098207935        train: [epoch 469] loss: 0.49316474245479347 test: [epoch 469] loss: 0.6363918499032805        train: [epoch 470] loss: 0.4775464092310882  test: [epoch 470] loss: 0.547569018257569         train: [epoch 471] loss: 0.48703203238251364 test: [epoch 471] loss: 0.5693285406163835        train: [epoch 472] loss: 0.46962697060550007 test: [epoch 472] loss: 0.5408555730697324        train: [epoch 473] loss: 0.49121079101198534 test: [epoch 473] loss: 0.5500118714703798        train: [epoch 474] loss: 0.47893171142195345 test: [epoch 474] loss: 0.5962247655670266        train: [epoch 475] loss: 0.4787799465248489  test: [epoch 475] loss: 0.5351580572498075        train: [epoch 476] loss: 0.4840924951344748  test: [epoch 476] loss: 0.5406208603285425        train: [epoch 477] loss: 0.4766857224015605  test: [epoch 477] loss: 0.680314142783206         train: [epoch 478] loss: 0.47211552468656787 test: [epoch 478] loss: 0.5361864738067513        train: [epoch 479] loss: 0.4776022789649564  test: [epoch 479] loss: 0.5403902079241327        train: [epoch 480] loss: 0.4748259562564925  test: [epoch 480] loss: 0.5594302604516351        train: [epoch 481] loss: 0.480379773236966   test: [epoch 481] loss: 0.537398628165972         train: [epoch 482] loss: 0.48300814216187743 test: [epoch 482] loss: 0.5372758532507871        train: [epoch 483] loss: 0.46807162942977476 test: [epoch 483] loss: 0.5514545492595954        train: [epoch 484] loss: 0.47263180239682145 test: [epoch 484] loss: 0.5353045661545038        train: [epoch 485] loss: 0.4712311212600031  test: [epoch 485] loss: 0.5387307047775888        train: [epoch 486] loss: 0.46417882275229594 test: [epoch 486] loss: 0.536125860152638         train: [epoch 487] loss: 0.4603138654910918  test: [epoch 487] loss: 0.5393759055402535        train: [epoch 488] loss: 0.46596377566204933 test: [epoch 488] loss: 0.5808314364148832        train: [epoch 489] loss: 0.47150405713834936 test: [epoch 489] loss: 0.5281561042738192        train: [epoch 490] loss: 0.45416713449200363 test: [epoch 490] loss: 0.5551371599813878        train: [epoch 491] loss: 0.4649627679484822  test: [epoch 491] loss: 0.5384037193714395        train: [epoch 492] loss: 0.46814752195426357 test: [epoch 492] loss: 0.531556259814308         train: [epoch 493] loss: 0.46022775425210444 test: [epoch 493] loss: 0.5360308865916353        train: [epoch 494] loss: 0.4614322875897559  test: [epoch 494] loss: 0.5298873734319742        train: [epoch 495] loss: 0.4564656666283136  test: [epoch 495] loss: 0.5430942170305427        train: [epoch 496] loss: 0.45192758164395214 test: [epoch 496] loss: 0.5584067015854187        train: [epoch 497] loss: 0.47314526293519593 test: [epoch 497] loss: 0.6119025604301731        train: [epoch 498] loss: 0.46518382226986665 test: [epoch 498] loss: 0.5766325319082708        train: [epoch 499] loss: 0.4652601152836468  test: [epoch 499] loss: 0.5459810324249821        train: [epoch 500] loss: 0.4519619793624041  test: [epoch 500] loss: 0.5808396395121672        train: [epoch 501] loss: 0.4539762801219035  test: [epoch 501] loss: 0.5457541208211893        train: [epoch 502] loss: 0.47032737319241325 test: [epoch 502] loss: 0.5528636579406722        train: [epoch 503] loss: 0.46367378692139627 test: [epoch 503] loss: 0.5643292487808441        train: [epoch 504] loss: 0.45506785257044025 test: [epoch 504] loss: 0.5676208884969364        train: [epoch 505] loss: 0.4583748133247905  test: [epoch 505] loss: 0.5378886004117781        train: [epoch 506] loss: 0.4731012992872658  test: [epoch 506] loss: 0.5598801184713558        train: [epoch 507] loss: 0.45138700110242086 test: [epoch 507] loss: 0.533842209543041         train: [epoch 508] loss: 0.44998919916640134 test: [epoch 508] loss: 0.5387210241489484        train: [epoch 509] loss: 0.45727551864466864 test: [epoch 509] loss: 0.5551676598712432        train: [epoch 510] loss: 0.4710856074002718  test: [epoch 510] loss: 0.5542333243509163        train: [epoch 511] loss: 0.46010935562224786 test: [epoch 511] loss: 0.572054342388665         train: [epoch 512] loss: 0.4532588526839388  test: [epoch 512] loss: 0.6077763316979374        train: [epoch 513] loss: 0.4558861434050595  test: [epoch 513] loss: 0.5408352077400883        train: [epoch 514] loss: 0.4457215508953092  test: [epoch 514] loss: 0.5429601412442815        train: [epoch 515] loss: 0.4851077854227962  test: [epoch 515] loss: 0.5373828950411689        train: [epoch 516] loss: 0.4758980182079904  test: [epoch 516] loss: 0.5340863234495196        train: [epoch 517] loss: 0.4567824914050655  test: [epoch 517] loss: 0.5414555196184034        train: [epoch 518] loss: 0.4541111705995262  test: [epoch 518] loss: 0.5382415149307255        train: [epoch 519] loss: 0.45510285108263326 test: [epoch 519] loss: 0.5397370138465151        train: [epoch 520] loss: 0.45169663628866147 test: [epoch 520] loss: 0.559227654473259         train: [epoch 521] loss: 0.48216879932598233 test: [epoch 521] loss: 0.5459812636075304        train: [epoch 522] loss: 0.4814633393652914  test: [epoch 522] loss: 0.5497891776178339        train: [epoch 523] loss: 0.4588389459406248  test: [epoch 523] loss: 0.538403572445796         train: [epoch 524] loss: 0.4486904463320109  test: [epoch 524] loss: 0.537992026134852         train: [epoch 525] loss: 0.4644137026975304  test: [epoch 525] loss: 0.565730935174428         train: [epoch 526] loss: 0.46874755371746546 test: [epoch 526] loss: 0.5383960971081574        train: [epoch 527] loss: 0.4573879440412244  test: [epoch 527] loss: 0.5495453545220805        train: [epoch 528] loss: 0.474871211034338   test: [epoch 528] loss: 0.5417582289328676        train: [epoch 529] loss: 0.45318708680932474 test: [epoch 529] loss: 0.5530900929055118        train: [epoch 530] loss: 0.4496256373608967  test: [epoch 530] loss: 0.5314451082839459        train: [epoch 531] loss: 0.44980426526819706 test: [epoch 531] loss: 0.6069876688985255        train: [epoch 532] loss: 0.4444841142185199  test: [epoch 532] loss: 0.5797182862056786        train: [epoch 533] loss: 0.44377312168939315 test: [epoch 533] loss: 0.5628639307665533        train: [epoch 534] loss: 0.45844394400758604 test: [epoch 534] loss: 0.5275943382488875        train: [epoch 535] loss: 0.44674446346572266 test: [epoch 535] loss: 0.5665720744441812        train: [epoch 536] loss: 0.44691088411339996 test: [epoch 536] loss: 0.5861189453103489        train: [epoch 537] loss: 0.462115257454629   test: [epoch 537] loss: 0.5335011994075236        train: [epoch 538] loss: 0.44353003618800707 test: [epoch 538] loss: 0.5451095725774242        train: [epoch 539] loss: 0.4318064869767922  test: [epoch 539] loss: 0.5495996410902078        train: [epoch 540] loss: 0.4549455599680523  test: [epoch 540] loss: 0.5360010572020739        train: [epoch 541] loss: 0.4369029013633084  test: [epoch 541] loss: 0.5359900754828913        train: [epoch 542] loss: 0.47028234756062737 test: [epoch 542] loss: 0.5343912095501938        train: [epoch 543] loss: 0.458584464610558   test: [epoch 543] loss: 0.5588053009057602        train: [epoch 544] loss: 0.46752910572120365 test: [epoch 544] loss: 0.5528302200053248        train: [epoch 545] loss: 0.4575473572834768  test: [epoch 545] loss: 0.5380231409272533        train: [epoch 546] loss: 0.45803084864085963 test: [epoch 546] loss: 0.5440915462008457        train: [epoch 547] loss: 0.4451780297972377  test: [epoch 547] loss: 0.565558011525205         train: [epoch 548] loss: 0.4497235143070322  test: [epoch 548] loss: 0.5368449385205587        train: [epoch 549] loss: 0.446379554572517   test: [epoch 549] loss: 0.5443163793217751        train: [epoch 550] loss: 0.4596478021702248  test: [epoch 550] loss: 0.5678399412308696        train: [epoch 551] loss: 0.46083672992959274 test: [epoch 551] loss: 0.5246319013246312        train: [epoch 552] loss: 0.46272333444029246 test: [epoch 552] loss: 0.5561482542027085        train: [epoch 553] loss: 0.4479519623759926  test: [epoch 553] loss: 0.5345545033156032        train: [epoch 554] loss: 0.4525788082361388  test: [epoch 554] loss: 0.5542475945808274        train: [epoch 555] loss: 0.45604936397864315 test: [epoch 555] loss: 0.5411176141067132        train: [epoch 556] loss: 0.43405335385558413 test: [epoch 556] loss: 0.5383864005279766        train: [epoch 557] loss: 0.44249744728071333 test: [epoch 557] loss: 0.5451316238388114        train: [epoch 558] loss: 0.4279241380641308  test: [epoch 558] loss: 0.5291460933029608        train: [epoch 559] loss: 0.44991739457289587 test: [epoch 559] loss: 0.5524058173023579        train: [epoch 560] loss: 0.426472032276613   test: [epoch 560] loss: 0.5389269134232765        train: [epoch 561] loss: 0.4531354434423545  test: [epoch 561] loss: 0.5612991847731442        train: [epoch 562] loss: 0.43969612301948285 test: [epoch 562] loss: 0.6242873639015434        train: [epoch 563] loss: 0.4398536180536152  test: [epoch 563] loss: 0.5494761828484859        train: [epoch 564] loss: 0.4364371244783781  test: [epoch 564] loss: 0.5357834588105876        train: [epoch 565] loss: 0.455193654203049   test: [epoch 565] loss: 0.5559094085038512        train: [epoch 566] loss: 0.437420168555746   test: [epoch 566] loss: 0.5388248796352142        train: [epoch 567] loss: 0.43744931618779337 test: [epoch 567] loss: 0.5376028275795925        train: [epoch 568] loss: 0.4389661766070913  test: [epoch 568] loss: 0.561289281647145         train: [epoch 569] loss: 0.439250336007214   test: [epoch 569] loss: 0.6064749950074578        train: [epoch 570] loss: 0.43483113726202877 test: [epoch 570] loss: 0.5342081334094808        train: [epoch 571] loss: 0.44207437042273506 test: [epoch 571] loss: 0.5371141321575825        train: [epoch 572] loss: 0.447143772657006   test: [epoch 572] loss: 0.5616490871782608        train: [epoch 573] loss: 0.44215560200450044 test: [epoch 573] loss: 0.545216676900197         train: [epoch 574] loss: 0.44045052330994966 test: [epoch 574] loss: 0.5557484557395629        train: [epoch 575] loss: 0.4438947882993222  test: [epoch 575] loss: 0.5523199351519008        train: [epoch 576] loss: 0.42865977950682427 test: [epoch 576] loss: 0.534755986284194         train: [epoch 577] loss: 0.43548644251255303 test: [epoch 577] loss: 0.5411056909201845        train: [epoch 578] loss: 0.44895638199301263 test: [epoch 578] loss: 0.5497967643202089        train: [epoch 579] loss: 0.44412279632370616 test: [epoch 579] loss: 0.6017253459639154        train: [epoch 580] loss: 0.44401019996824637 test: [epoch 580] loss: 0.5639618926356909        train: [epoch 581] loss: 0.46611061265074716 test: [epoch 581] loss: 0.5589210716552914        train: [epoch 582] loss: 0.431565309785029   test: [epoch 582] loss: 0.538454761937186         train: [epoch 583] loss: 0.4367063019885091  test: [epoch 583] loss: 0.5624172927099005        train: [epoch 584] loss: 0.4577700797306558  test: [epoch 584] loss: 0.5538512088546835        train: [epoch 585] loss: 0.43668643264168466 test: [epoch 585] loss: 0.5449723964836158        train: [epoch 586] loss: 0.4487816157579635  test: [epoch 586] loss: 0.5522814901531481        train: [epoch 587] loss: 0.4379723028191284  test: [epoch 587] loss: 0.5459913395798596        train: [epoch 588] loss: 0.43164756824768646 test: [epoch 588] loss: 0.5819481904840478        train: [epoch 589] loss: 0.4457718223713464  test: [epoch 589] loss: 0.5404941618054031        train: [epoch 590] loss: 0.44745861266535186 test: [epoch 590] loss: 0.5288162027007673        train: [epoch 591] loss: 0.44230835207233804 test: [epoch 591] loss: 0.5333353013494199        train: [epoch 592] loss: 0.4398641954976329  test: [epoch 592] loss: 0.5355801851808255        train: [epoch 593] loss: 0.43584838816264454 test: [epoch 593] loss: 0.566279014650588         train: [epoch 594] loss: 0.42942106112676043 test: [epoch 594] loss: 0.5349966580627773        train: [epoch 595] loss: 0.426425553725086   test: [epoch 595] loss: 0.5690363879922202        train: [epoch 596] loss: 0.427393517476151   test: [epoch 596] loss: 0.55576019650129          train: [epoch 597] loss: 0.4500695900791881  test: [epoch 597] loss: 0.5443681986162625        train: [epoch 598] loss: 0.4285047787222517  test: [epoch 598] loss: 0.5551310050636119        train: [epoch 599] loss: 0.4220718467173269  test: [epoch 599] loss: 0.5710800526443612        train: [epoch 600] loss: 0.4478065133267696  test: [epoch 600] loss: 0.548106183528831         train: [epoch 601] loss: 0.42447887441295645 test: [epoch 601] loss: 0.5365138503606524        train: [epoch 602] loss: 0.44675546597187293 test: [epoch 602] loss: 0.5518078649293543        train: [epoch 603] loss: 0.44320832831916895 test: [epoch 603] loss: 0.5398430162543535        train: [epoch 604] loss: 0.43046695090495246 test: [epoch 604] loss: 0.5737448670227066        train: [epoch 605] loss: 0.41007598547910573 test: [epoch 605] loss: 0.5580624632174063        train: [epoch 606] loss: 0.43384852803415025 test: [epoch 606] loss: 0.5520061091893486        train: [epoch 607] loss: 0.4364595693888822  test: [epoch 607] loss: 0.5456211040453534        train: [epoch 608] loss: 0.42361910997106295 test: [epoch 608] loss: 0.5444372903782129        train: [epoch 609] loss: 0.41240308891461847 test: [epoch 609] loss: 0.5370255321012275        train: [epoch 610] loss: 0.42758033727082145 test: [epoch 610] loss: 0.5543064350920935        train: [epoch 611] loss: 0.42763727972329085 test: [epoch 611] loss: 0.5418406020496684        train: [epoch 612] loss: 0.4448423996728903  test: [epoch 612] loss: 0.5573424834859866        train: [epoch 613] loss: 0.42157619290538734 test: [epoch 613] loss: 0.5412752972527811        train: [epoch 614] loss: 0.4247637317981153  test: [epoch 614] loss: 0.5383592567971016        train: [epoch 615] loss: 0.4482433048376982  test: [epoch 615] loss: 0.5282993398497993        train: [epoch 616] loss: 0.4384644328596043  test: [epoch 616] loss: 0.5362556069720416        train: [epoch 617] loss: 0.4430218979286874  test: [epoch 617] loss: 0.5469555798148381        train: [epoch 618] loss: 0.41932804910414323 test: [epoch 618] loss: 0.5421966602135697        train: [epoch 619] loss: 0.43540490379256125 test: [epoch 619] loss: 0.5321600015201633        train: [epoch 620] loss: 0.4221459212187496  test: [epoch 620] loss: 0.5364280572797891        train: [epoch 621] loss: 0.43208225008472756 test: [epoch 621] loss: 0.5443536576600112        train: [epoch 622] loss: 0.43700107590742826 test: [epoch 622] loss: 0.5491316816192855        train: [epoch 623] loss: 0.4322549150906069  test: [epoch 623] loss: 0.6043689809025189        train: [epoch 624] loss: 0.44597862897991264 test: [epoch 624] loss: 0.5335915275309221        train: [epoch 625] loss: 0.4340379975764884  test: [epoch 625] loss: 0.5505531950379139        train: [epoch 626] loss: 0.42962275367064295 test: [epoch 626] loss: 0.5512520939870776        train: [epoch 627] loss: 0.424930480000969   test: [epoch 627] loss: 0.5387779722238417        train: [epoch 628] loss: 0.4309043795661945  test: [epoch 628] loss: 0.5410504456263898        train: [epoch 629] loss: 0.41658751023240953 test: [epoch 629] loss: 0.5349672001343556        train: [epoch 630] loss: 0.4101587005320968  test: [epoch 630] loss: 0.548582264188843         train: [epoch 631] loss: 0.4159357838835351  test: [epoch 631] loss: 0.5566196980823156        train: [epoch 632] loss: 0.4131020653302186  test: [epoch 632] loss: 0.5392884506187368        train: [epoch 633] loss: 0.4212180500663469  test: [epoch 633] loss: 0.5470399174513516        train: [epoch 634] loss: 0.4306804446599696  test: [epoch 634] loss: 0.5340324200736808        train: [epoch 635] loss: 0.4375291795428813  test: [epoch 635] loss: 0.5467051286891323        train: [epoch 636] loss: 0.4232656139779824  test: [epoch 636] loss: 0.5336042793543152        train: [epoch 637] loss: 0.428318545833629   test: [epoch 637] loss: 0.5365605653206671        train: [epoch 638] loss: 0.43592608936739924 test: [epoch 638] loss: 0.533900887457288         train: [epoch 639] loss: 0.4130682252272064  test: [epoch 639] loss: 0.537748950107898         train: [epoch 640] loss: 0.4300842557245854  test: [epoch 640] loss: 0.5403502292622485        train: [epoch 641] loss: 0.4347880149796715  test: [epoch 641] loss: 0.5474670381690895        train: [epoch 642] loss: 0.43039225477914467 test: [epoch 642] loss: 0.5491087816045187        train: [epoch 643] loss: 0.4353079835783942  test: [epoch 643] loss: 0.5352958756372628        train: [epoch 644] loss: 0.41008540785565656 test: [epoch 644] loss: 0.5361584559059152        train: [epoch 645] loss: 0.4268773084474023  test: [epoch 645] loss: 0.5339908717634801        train: [epoch 646] loss: 0.4219171003990301  test: [epoch 646] loss: 0.539423161140494         train: [epoch 647] loss: 0.4327254921541192  test: [epoch 647] loss: 0.5268031671177813        train: [epoch 648] loss: 0.3990467933033533  test: [epoch 648] loss: 0.5739715862321448        train: [epoch 649] loss: 0.4080782667704125  test: [epoch 649] loss: 0.5367512003931003        train: [epoch 650] loss: 0.4204461042732905  test: [epoch 650] loss: 0.5535359822143182        train: [epoch 651] loss: 0.4172941305596195  test: [epoch 651] loss: 0.5359366918797382        train: [epoch 652] loss: 0.4260188206948135  test: [epoch 652] loss: 0.5315053398862306        train: [epoch 653] loss: 0.4200212244448561  test: [epoch 653] loss: 0.5815666204805221        train: [epoch 654] loss: 0.41274337199902267 test: [epoch 654] loss: 0.5509702213648736        train: [epoch 655] loss: 0.4114526941698804  test: [epoch 655] loss: 0.5308442226619869        train: [epoch 656] loss: 0.4193150831040061  test: [epoch 656] loss: 0.5577974888933518        train: [epoch 657] loss: 0.4133961958724382  test: [epoch 657] loss: 0.5296995496209486        train: [epoch 658] loss: 0.41148305925990764 test: [epoch 658] loss: 0.530638483317494         train: [epoch 659] loss: 0.4164330542320782  test: [epoch 659] loss: 0.5312155033650284        train: [epoch 660] loss: 0.4269682031755388  test: [epoch 660] loss: 0.542970539736337         train: [epoch 661] loss: 0.42329385660258173 test: [epoch 661] loss: 0.5582878366225804        train: [epoch 662] loss: 0.4274369518092358  test: [epoch 662] loss: 0.5342056140195004        train: [epoch 663] loss: 0.3994877929779411  test: [epoch 663] loss: 0.5949862153848895        train: [epoch 664] loss: 0.4121169236497497  test: [epoch 664] loss: 0.5450351210753062        train: [epoch 665] loss: 0.4359929652975274  test: [epoch 665] loss: 0.5341982254435322        train: [epoch 666] loss: 0.42607165460435337 test: [epoch 666] loss: 0.5535246964611114        train: [epoch 667] loss: 0.4150060322220466  test: [epoch 667] loss: 0.5400790281334326        train: [epoch 668] loss: 0.4073143475242471  test: [epoch 668] loss: 0.5399982012331673        train: [epoch 669] loss: 0.43691336062830594 test: [epoch 669] loss: 0.533716482365098         train: [epoch 670] loss: 0.4387655946636625  test: [epoch 670] loss: 0.5335559916333846        train: [epoch 671] loss: 0.4279880259018947  test: [epoch 671] loss: 0.5654416889370357        train: [epoch 672] loss: 0.4248530525687506  test: [epoch 672] loss: 0.5632623954197284        train: [epoch 673] loss: 0.41774804149333045 test: [epoch 673] loss: 0.5412744450817779        train: [epoch 674] loss: 0.4260753473701462  test: [epoch 674] loss: 0.5738649730673195        train: [epoch 675] loss: 0.41066456000460094 test: [epoch 675] loss: 0.5536505548228055        train: [epoch 676] loss: 0.41604618249219294 test: [epoch 676] loss: 0.5457320015397777        train: [epoch 677] loss: 0.397836993101136   test: [epoch 677] loss: 0.5289189407363849        train: [epoch 678] loss: 0.42258129393211474 test: [epoch 678] loss: 0.5398426300713507        train: [epoch 679] loss: 0.3992699050323199  test: [epoch 679] loss: 0.5382461475978746        train: [epoch 680] loss: 0.432912727715229   test: [epoch 680] loss: 0.5707917833593759        train: [epoch 681] loss: 0.3878108433776715  test: [epoch 681] loss: 0.5301782753228126        train: [epoch 682] loss: 0.43783264303142855 test: [epoch 682] loss: 0.5438912607890096        train: [epoch 683] loss: 0.4234758016768036  test: [epoch 683] loss: 0.5484057278340295        train: [epoch 684] loss: 0.43419297973013216 test: [epoch 684] loss: 0.532222833961652         train: [epoch 685] loss: 0.4328963617819864  test: [epoch 685] loss: 0.5384147255997207        train: [epoch 686] loss: 0.4099775714606957  test: [epoch 686] loss: 0.5384934880836117        train: [epoch 687] loss: 0.418334526072764   test: [epoch 687] loss: 0.5320240950405437        train: [epoch 688] loss: 0.4220484996313632  test: [epoch 688] loss: 0.5484180834247997        train: [epoch 689] loss: 0.4295244872218883  test: [epoch 689] loss: 0.5285743934060653        train: [epoch 690] loss: 0.4307756873264492  test: [epoch 690] loss: 0.5484388053838598        train: [epoch 691] loss: 0.43920156526299453 test: [epoch 691] loss: 0.5453143822362402        train: [epoch 692] loss: 0.41007602418927436 test: [epoch 692] loss: 0.5397570445353079        train: [epoch 693] loss: 0.39393722094315453 test: [epoch 693] loss: 0.5411440536544986        train: [epoch 694] loss: 0.40367302072281813 test: [epoch 694] loss: 0.5321788199429968        train: [epoch 695] loss: 0.39994678884000273 test: [epoch 695] loss: 0.5503868009219322        train: [epoch 696] loss: 0.41058652165661713 test: [epoch 696] loss: 0.5654003053123307        train: [epoch 697] loss: 0.4174574301033224  test: [epoch 697] loss: 0.5290935217197821        train: [epoch 698] loss: 0.41355077635353044 test: [epoch 698] loss: 0.5290218966651744        train: [epoch 699] loss: 0.4202629772922042  test: [epoch 699] loss: 0.5458103985638172        train: [epoch 700] loss: 0.4201331385088209  test: [epoch 700] loss: 0.5337633215422576        train: [epoch 701] loss: 0.3994170420768399  test: [epoch 701] loss: 0.5450463843276268        train: [epoch 702] loss: 0.42552275231521053 test: [epoch 702] loss: 0.5525005451942613        train: [epoch 703] loss: 0.4067732077752074  test: [epoch 703] loss: 0.5421930302316988        train: [epoch 704] loss: 0.4317047485444493  test: [epoch 704] loss: 0.5422983354741165        train: [epoch 705] loss: 0.4288581050866647  test: [epoch 705] loss: 0.5402121449466833        train: [epoch 706] loss: 0.4118269667827392  test: [epoch 706] loss: 0.5397057112283946        train: [epoch 707] loss: 0.4024150642915354  test: [epoch 707] loss: 0.5296459796319879        train: [epoch 708] loss: 0.4131117823231548  test: [epoch 708] loss: 0.5495184276176448        train: [epoch 709] loss: 0.40553618842357847 test: [epoch 709] loss: 0.5610227380785185        train: [epoch 710] loss: 0.41745649473128194 test: [epoch 710] loss: 0.5297470851076249        train: [epoch 711] loss: 0.4255223854967646  test: [epoch 711] loss: 0.5472343136206308        train: [epoch 712] loss: 0.4263420259953639  test: [epoch 712] loss: 0.5319458690005447        train: [epoch 713] loss: 0.4229367316749051  test: [epoch 713] loss: 0.5373082207698915        train: [epoch 714] loss: 0.4042085358840799  test: [epoch 714] loss: 0.5324249504239544        train: [epoch 715] loss: 0.397161979722599   test: [epoch 715] loss: 0.5421987798005337        train: [epoch 716] loss: 0.4047094800730375  test: [epoch 716] loss: 0.537845546070967         train: [epoch 717] loss: 0.3948003714830913  test: [epoch 717] loss: 0.5521489386761839        train: [epoch 718] loss: 0.40017462128013304 test: [epoch 718] loss: 0.5473121244577801        train: [epoch 719] loss: 0.4183198716626404  test: [epoch 719] loss: 0.5415777482981579        