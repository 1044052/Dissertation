train: [epoch 0] loss: 5.4514661912817255    test: [epoch 0] loss: 4.622316091759316           train: [epoch 1] loss: 2.8247519904615714    test: [epoch 1] loss: 1.5315431381737712          train: [epoch 2] loss: 1.6088889578778816    test: [epoch 2] loss: 0.9340145249582411          train: [epoch 3] loss: 1.37409967573087      test: [epoch 3] loss: 0.7165408300978774          train: [epoch 4] loss: 1.2803717901092615    test: [epoch 4] loss: 0.7230157113458328          train: [epoch 5] loss: 1.1666860415503875    test: [epoch 5] loss: 0.7016123761822256          train: [epoch 6] loss: 1.115059737775416     test: [epoch 6] loss: 0.7410578429254587          train: [epoch 7] loss: 1.075822197243423     test: [epoch 7] loss: 0.7268181698364334          train: [epoch 8] loss: 1.0366381250069234    test: [epoch 8] loss: 0.6956403620884539          train: [epoch 9] loss: 1.0180880781745865    test: [epoch 9] loss: 0.668108018211756           train: [epoch 10] loss: 0.998301960629921    test: [epoch 10] loss: 0.691518679299752          train: [epoch 11] loss: 0.9799343120095472   test: [epoch 11] loss: 0.7477890833717477         train: [epoch 12] loss: 0.9880980758835668   test: [epoch 12] loss: 0.7466364680058226         train: [epoch 13] loss: 0.9766197417899436   test: [epoch 13] loss: 0.8340319735244867         train: [epoch 14] loss: 1.0020154420152787   test: [epoch 14] loss: 0.8095580191169212         train: [epoch 15] loss: 0.9716460689890336   test: [epoch 15] loss: 0.6625874903893044         train: [epoch 16] loss: 0.9483929229738172   test: [epoch 16] loss: 0.7710031886385118         train: [epoch 17] loss: 0.954446113466867    test: [epoch 17] loss: 0.6978504636405971         train: [epoch 18] loss: 0.9470425154625791   test: [epoch 18] loss: 0.7369128309111229         train: [epoch 19] loss: 0.9293981014311311   test: [epoch 19] loss: 0.6878206371977363         train: [epoch 20] loss: 0.9327842578993163   test: [epoch 20] loss: 0.6558778538726572         train: [epoch 21] loss: 0.925311605638455    test: [epoch 21] loss: 0.7022398288461048         train: [epoch 22] loss: 0.9102820769642211   test: [epoch 22] loss: 0.6502800507933872         train: [epoch 23] loss: 0.9200648152365792   test: [epoch 23] loss: 0.6806349102254285         train: [epoch 24] loss: 0.9144577261714933   test: [epoch 24] loss: 0.6555797272403893         train: [epoch 25] loss: 0.9010507812762691   test: [epoch 25] loss: 0.6584928894788122         train: [epoch 26] loss: 0.884583025654134    test: [epoch 26] loss: 0.6530965612777079         train: [epoch 27] loss: 0.8735196083033824   test: [epoch 27] loss: 0.6429692167173164         train: [epoch 28] loss: 0.8839231001609368   test: [epoch 28] loss: 0.6557251286002067         train: [epoch 29] loss: 0.8974858223542379   test: [epoch 29] loss: 0.6585882072295215         train: [epoch 30] loss: 0.8656014646567893   test: [epoch 30] loss: 0.6712949465416538         train: [epoch 31] loss: 0.8704341709983817   test: [epoch 31] loss: 0.6514108518108166         train: [epoch 32] loss: 0.8565834041000425   test: [epoch 32] loss: 0.6194614218682171         train: [epoch 33] loss: 0.8576968641658897   test: [epoch 33] loss: 0.6987146455697969         train: [epoch 34] loss: 0.869081194868473    test: [epoch 34] loss: 0.6319556668310344         train: [epoch 35] loss: 0.8384811034872102   test: [epoch 35] loss: 0.6245878772116638         train: [epoch 36] loss: 0.8470181162934751   test: [epoch 36] loss: 0.6967858794670264         train: [epoch 37] loss: 0.8312428238528469   test: [epoch 37] loss: 0.6386921079817102         train: [epoch 38] loss: 0.8308704604531395   test: [epoch 38] loss: 0.6639710243392425         train: [epoch 39] loss: 0.8349824474642783   test: [epoch 39] loss: 0.6038718849601126         train: [epoch 40] loss: 0.8343500514923671   test: [epoch 40] loss: 0.613792969353943          train: [epoch 41] loss: 0.8134070719043623   test: [epoch 41] loss: 0.6161708580687841         train: [epoch 42] loss: 0.8071752409361099   test: [epoch 42] loss: 0.7996422404839552         train: [epoch 43] loss: 0.8138851872920384   test: [epoch 43] loss: 0.6156522157638645         train: [epoch 44] loss: 0.8031899957498765   test: [epoch 44] loss: 0.7164786280231058         train: [epoch 45] loss: 0.8126031077965793   test: [epoch 45] loss: 0.7145504701544352         train: [epoch 46] loss: 0.8001513489408      test: [epoch 46] loss: 0.5918460344597668         train: [epoch 47] loss: 0.7911741423870824   test: [epoch 47] loss: 0.6274338336253599         train: [epoch 48] loss: 0.8184705757289971   test: [epoch 48] loss: 0.5873960858048815         train: [epoch 49] loss: 0.8037466334662479   test: [epoch 49] loss: 0.6240658589768101         train: [epoch 50] loss: 0.7864919212168582   test: [epoch 50] loss: 0.6064791911125808         train: [epoch 51] loss: 0.7836858582180094   test: [epoch 51] loss: 0.5960871221326853         train: [epoch 52] loss: 0.7878073083335262   test: [epoch 52] loss: 0.6400747617871113         train: [epoch 53] loss: 0.7853443684912549   test: [epoch 53] loss: 0.6203439076100574         train: [epoch 54] loss: 0.779911843986075    test: [epoch 54] loss: 0.6093964480538633         train: [epoch 55] loss: 0.7868136468107978   test: [epoch 55] loss: 0.6827104465838475         train: [epoch 56] loss: 0.7965712303925138   test: [epoch 56] loss: 0.5826978467114456         train: [epoch 57] loss: 0.7753705553834496   test: [epoch 57] loss: 0.6645597733568029         train: [epoch 58] loss: 0.8012697930269376   test: [epoch 58] loss: 0.5934556404348865         train: [epoch 59] loss: 0.7754783874535952   test: [epoch 59] loss: 0.5882934719343418         train: [epoch 60] loss: 0.7758022215286723   test: [epoch 60] loss: 0.6009922081519306         train: [epoch 61] loss: 0.7621815636443388   test: [epoch 61] loss: 0.6298357837514673         train: [epoch 62] loss: 0.7600978965675982   test: [epoch 62] loss: 0.5794421314932187         train: [epoch 63] loss: 0.7778033978892417   test: [epoch 63] loss: 0.5698614895975587         train: [epoch 64] loss: 0.7554615508746542   test: [epoch 64] loss: 0.5654837900942884         train: [epoch 65] loss: 0.7583309663190947   test: [epoch 65] loss: 0.6186562265959398         train: [epoch 66] loss: 0.7653996071223017   test: [epoch 66] loss: 0.5824356569298521         train: [epoch 67] loss: 0.7590875149906039   test: [epoch 67] loss: 0.588898234087937          train: [epoch 68] loss: 0.7611981651955911   test: [epoch 68] loss: 0.5848952377174885         train: [epoch 69] loss: 0.7562006321807424   test: [epoch 69] loss: 0.5726963286769164         train: [epoch 70] loss: 0.7513009885993445   test: [epoch 70] loss: 0.5624894809221999         train: [epoch 71] loss: 0.7514208307238135   test: [epoch 71] loss: 0.5719685221010053         train: [epoch 72] loss: 0.7379383029100451   test: [epoch 72] loss: 0.5881881532039909         train: [epoch 73] loss: 0.7412795272801974   test: [epoch 73] loss: 0.5448710622550614         train: [epoch 74] loss: 0.7482912026541567   test: [epoch 74] loss: 0.6462060210716242         train: [epoch 75] loss: 0.7523155544069677   test: [epoch 75] loss: 0.588642908793889          train: [epoch 76] loss: 0.7384804783172817   test: [epoch 76] loss: 0.5659438547930273         train: [epoch 77] loss: 0.7599651009575263   test: [epoch 77] loss: 0.5936706265793497         train: [epoch 78] loss: 0.726350091957574    test: [epoch 78] loss: 0.5789837333348429         train: [epoch 79] loss: 0.734680843021611    test: [epoch 79] loss: 0.572015445652503          train: [epoch 80] loss: 0.74255118981759     test: [epoch 80] loss: 0.5662605345987328         train: [epoch 81] loss: 0.7385268780136274   test: [epoch 81] loss: 0.610536006319191          train: [epoch 82] loss: 0.7368465497155876   test: [epoch 82] loss: 0.5474236682784116         train: [epoch 83] loss: 0.7415391383729616   test: [epoch 83] loss: 0.6884708293986498         train: [epoch 84] loss: 0.7460974454344058   test: [epoch 84] loss: 0.5854410041672743         train: [epoch 85] loss: 0.7292742073909863   test: [epoch 85] loss: 0.5610400880893512         train: [epoch 86] loss: 0.71804880926711     test: [epoch 86] loss: 0.5985207588463352         train: [epoch 87] loss: 0.7312146972474928   test: [epoch 87] loss: 0.5520412241965644         train: [epoch 88] loss: 0.7360809373923874   test: [epoch 88] loss: 0.5580467450602123         train: [epoch 89] loss: 0.7137767565933929   test: [epoch 89] loss: 0.6668731351677538         train: [epoch 90] loss: 0.7247436460870538   test: [epoch 90] loss: 0.5572152321137189         train: [epoch 91] loss: 0.707260125626616    test: [epoch 91] loss: 0.5532025741965506         train: [epoch 92] loss: 0.7242707770775497   test: [epoch 92] loss: 0.7496807279301134         train: [epoch 93] loss: 0.734534527752226    test: [epoch 93] loss: 0.5700247926524307         train: [epoch 94] loss: 0.7119401395569518   test: [epoch 94] loss: 0.5719473257972301         train: [epoch 95] loss: 0.7207526107414397   test: [epoch 95] loss: 0.5461959121620368         train: [epoch 96] loss: 0.714216239368502    test: [epoch 96] loss: 0.5431185762783287         train: [epoch 97] loss: 0.7083954998661044   test: [epoch 97] loss: 0.5576990176176918         train: [epoch 98] loss: 0.7121571401467616   test: [epoch 98] loss: 0.7277850399615847         train: [epoch 99] loss: 0.7152666559188757   test: [epoch 99] loss: 0.5922374752795504         train: [epoch 100] loss: 0.7108585139362634  test: [epoch 100] loss: 0.5786491137225598        train: [epoch 101] loss: 0.7085479102703031  test: [epoch 101] loss: 0.6069401806173667        train: [epoch 102] loss: 0.7295819868985735  test: [epoch 102] loss: 0.5875823983467631        train: [epoch 103] loss: 0.6982759496637128  test: [epoch 103] loss: 0.6229116994410132        train: [epoch 104] loss: 0.6974944082624254  test: [epoch 104] loss: 0.5551546642892503        train: [epoch 105] loss: 0.7002472549561419  test: [epoch 105] loss: 0.5962536833741673        train: [epoch 106] loss: 0.700071858697045   test: [epoch 106] loss: 0.5935869957069136        train: [epoch 107] loss: 0.7064521258275721  test: [epoch 107] loss: 0.5580727020820828        train: [epoch 108] loss: 0.7059810386496869  test: [epoch 108] loss: 0.5428898890310931        train: [epoch 109] loss: 0.7239737795610957  test: [epoch 109] loss: 0.5698873389859423        train: [epoch 110] loss: 0.7133985104326535  test: [epoch 110] loss: 0.5993631230632124        train: [epoch 111] loss: 0.6911045377160828  test: [epoch 111] loss: 0.5682140066326699        train: [epoch 112] loss: 0.6962016002344076  test: [epoch 112] loss: 0.5531882598424339        train: [epoch 113] loss: 0.6936713040836295  test: [epoch 113] loss: 0.6824548388850721        train: [epoch 114] loss: 0.6987715969027049  test: [epoch 114] loss: 0.7064207637074829        train: [epoch 115] loss: 0.6946209895212829  test: [epoch 115] loss: 0.5421727260140923        train: [epoch 116] loss: 0.6819001804423875  test: [epoch 116] loss: 0.595925211431611         train: [epoch 117] loss: 0.6780165364887071  test: [epoch 117] loss: 0.5578226447643013        train: [epoch 118] loss: 0.7039479478651745  test: [epoch 118] loss: 0.7295050927802229        train: [epoch 119] loss: 0.7030344427398194  test: [epoch 119] loss: 0.5732588358663229        train: [epoch 120] loss: 0.6933806314033175  test: [epoch 120] loss: 0.5415106704858218        train: [epoch 121] loss: 0.6951162901172072  test: [epoch 121] loss: 0.5263158243567987        train: [epoch 122] loss: 0.6704309252958183  test: [epoch 122] loss: 0.5775541111324964        train: [epoch 123] loss: 0.6688002140797341  test: [epoch 123] loss: 0.6289722310631096        train: [epoch 124] loss: 0.6897245258442428  test: [epoch 124] loss: 0.5176210290735573        train: [epoch 125] loss: 0.679495287980838   test: [epoch 125] loss: 0.5642150785811867        train: [epoch 126] loss: 0.6688019038209433  test: [epoch 126] loss: 0.5930639629319527        train: [epoch 127] loss: 0.6815808676188375  test: [epoch 127] loss: 0.6490178227319499        train: [epoch 128] loss: 0.6856725485417142  test: [epoch 128] loss: 0.5815429016719312        train: [epoch 129] loss: 0.666998987893423   test: [epoch 129] loss: 0.6421943363523736        train: [epoch 130] loss: 0.6760328004309482  test: [epoch 130] loss: 0.5527757829352005        train: [epoch 131] loss: 0.687975511969277   test: [epoch 131] loss: 0.5409527627973105        train: [epoch 132] loss: 0.6844906396723973  test: [epoch 132] loss: 0.7198731066180794        train: [epoch 133] loss: 0.6837048737065787  test: [epoch 133] loss: 0.5382616557744501        train: [epoch 134] loss: 0.6785270316192819  test: [epoch 134] loss: 0.5931223670849409        train: [epoch 135] loss: 0.6736835568533122  test: [epoch 135] loss: 0.5360314753150035        train: [epoch 136] loss: 0.6913988416388743  test: [epoch 136] loss: 0.5785203739120448        train: [epoch 137] loss: 0.6711275147399539  test: [epoch 137] loss: 0.6263081829041686        train: [epoch 138] loss: 0.6869553614146671  test: [epoch 138] loss: 0.712707292603551         train: [epoch 139] loss: 0.6789986804216461  test: [epoch 139] loss: 0.5643267219236041        train: [epoch 140] loss: 0.6705001822181167  test: [epoch 140] loss: 0.5945202380313762        train: [epoch 141] loss: 0.6791157237663495  test: [epoch 141] loss: 0.5531890885643966        train: [epoch 142] loss: 0.680856257428932   test: [epoch 142] loss: 0.6380922808563526        train: [epoch 143] loss: 0.67681707152032    test: [epoch 143] loss: 0.5394189715992568        train: [epoch 144] loss: 0.6699988998259886  test: [epoch 144] loss: 0.7034776052027559        train: [epoch 145] loss: 0.678526038652271   test: [epoch 145] loss: 0.5886584816867667        train: [epoch 146] loss: 0.6719312658464196  test: [epoch 146] loss: 0.5783728776068828        train: [epoch 147] loss: 0.6652200237090139  test: [epoch 147] loss: 0.6090230190550551        train: [epoch 148] loss: 0.682917798378898   test: [epoch 148] loss: 0.5977519993425641        train: [epoch 149] loss: 0.6647976960164883  test: [epoch 149] loss: 0.5717803947902182        train: [epoch 150] loss: 0.6729320453029206  test: [epoch 150] loss: 0.5348334010568874        train: [epoch 151] loss: 0.6680924476889152  test: [epoch 151] loss: 0.575349116632618         train: [epoch 152] loss: 0.659182782515697   test: [epoch 152] loss: 0.6320194408842504        train: [epoch 153] loss: 0.6614472935696298  test: [epoch 153] loss: 0.5833026715720554        train: [epoch 154] loss: 0.6735560728126379  test: [epoch 154] loss: 0.5262985442690546        train: [epoch 155] loss: 0.6612608989975995  test: [epoch 155] loss: 0.5345530960035224        train: [epoch 156] loss: 0.6790713280506032  test: [epoch 156] loss: 0.5610198783376343        train: [epoch 157] loss: 0.6694335482902709  test: [epoch 157] loss: 0.6055682354501324        train: [epoch 158] loss: 0.6838923205457996  test: [epoch 158] loss: 0.5510784058433749        train: [epoch 159] loss: 0.6567221657465343  test: [epoch 159] loss: 0.5549324392379203        train: [epoch 160] loss: 0.6570442972296182  test: [epoch 160] loss: 0.6412352446181971        train: [epoch 161] loss: 0.6587492031944022  test: [epoch 161] loss: 0.5435848254782861        train: [epoch 162] loss: 0.6617120545245188  test: [epoch 162] loss: 0.6257212773333595        train: [epoch 163] loss: 0.6561148679025426  test: [epoch 163] loss: 0.5814264558622195        train: [epoch 164] loss: 0.650895259339258   test: [epoch 164] loss: 0.5326215284536325        train: [epoch 165] loss: 0.6721634916903031  test: [epoch 165] loss: 0.535789254560653         train: [epoch 166] loss: 0.6562400111181408  test: [epoch 166] loss: 0.5432269038149652        train: [epoch 167] loss: 0.664380519861283   test: [epoch 167] loss: 0.5802794239230175        train: [epoch 168] loss: 0.6347797339414423  test: [epoch 168] loss: 0.5113565591505612        train: [epoch 169] loss: 0.6495036332317388  test: [epoch 169] loss: 0.5567485642582566        train: [epoch 170] loss: 0.6472323930360286  test: [epoch 170] loss: 0.5392222453329932        train: [epoch 171] loss: 0.6661861427312719  test: [epoch 171] loss: 0.5163042490152675        train: [epoch 172] loss: 0.6474390546767597  test: [epoch 172] loss: 0.5467281307843708        train: [epoch 173] loss: 0.6553295449495948  test: [epoch 173] loss: 0.5296579490766781        train: [epoch 174] loss: 0.6330662028416629  test: [epoch 174] loss: 0.5223307507450514        train: [epoch 175] loss: 0.639180430512604   test: [epoch 175] loss: 0.5116690550297173        train: [epoch 176] loss: 0.6641711146884747  test: [epoch 176] loss: 0.546447423072636         train: [epoch 177] loss: 0.6431233259223451  test: [epoch 177] loss: 0.5526126352978273        train: [epoch 178] loss: 0.6404685645788625  test: [epoch 178] loss: 0.5841686616122451        train: [epoch 179] loss: 0.6543442635807666  test: [epoch 179] loss: 0.5473505105815603        train: [epoch 180] loss: 0.6522329785517375  test: [epoch 180] loss: 0.6108854661988085        train: [epoch 181] loss: 0.63722674436195    test: [epoch 181] loss: 0.5365884874272516        train: [epoch 182] loss: 0.6440668257123205  test: [epoch 182] loss: 0.5989560960896807        train: [epoch 183] loss: 0.6430248218247785  test: [epoch 183] loss: 0.5676048642334064        train: [epoch 184] loss: 0.6534867914338106  test: [epoch 184] loss: 0.5237539533136254        train: [epoch 185] loss: 0.6359418180709124  test: [epoch 185] loss: 0.5301559729244083        train: [epoch 186] loss: 0.6378846129509577  test: [epoch 186] loss: 0.5847685469572687        train: [epoch 187] loss: 0.6325265581928438  test: [epoch 187] loss: 0.6172037000499765        train: [epoch 188] loss: 0.6388265092109942  test: [epoch 188] loss: 0.5295584576500573        train: [epoch 189] loss: 0.6501971657697893  test: [epoch 189] loss: 0.5762541053113671        train: [epoch 190] loss: 0.6378555586602289  test: [epoch 190] loss: 0.5633136506164449        train: [epoch 191] loss: 0.6657348462323602  test: [epoch 191] loss: 0.5201319786724207        train: [epoch 192] loss: 0.6529637226875978  test: [epoch 192] loss: 0.551404911365212         train: [epoch 193] loss: 0.6250001572762764  test: [epoch 193] loss: 0.6360274866341119        train: [epoch 194] loss: 0.6493870822034731  test: [epoch 194] loss: 0.5270653973506604        train: [epoch 195] loss: 0.6363189886965105  test: [epoch 195] loss: 0.5316637476873194        train: [epoch 196] loss: 0.6337377285195638  test: [epoch 196] loss: 0.5929670384575552        train: [epoch 197] loss: 0.6448795759851138  test: [epoch 197] loss: 0.532533011167734         train: [epoch 198] loss: 0.6493199672579604  test: [epoch 198] loss: 0.569620660098843         train: [epoch 199] loss: 0.6417018389502054  test: [epoch 199] loss: 0.5407359755551647        train: [epoch 200] loss: 0.6520715260603696  test: [epoch 200] loss: 0.5196248128668882        train: [epoch 201] loss: 0.6369543184340971  test: [epoch 201] loss: 0.5944650123902363        train: [epoch 202] loss: 0.6497964186520977  test: [epoch 202] loss: 0.5310379810229964        train: [epoch 203] loss: 0.6460683912792874  test: [epoch 203] loss: 0.5394616125136925        train: [epoch 204] loss: 0.6331281846955389  test: [epoch 204] loss: 0.5520186543397237        train: [epoch 205] loss: 0.6449274152678631  test: [epoch 205] loss: 0.5566619938533014        train: [epoch 206] loss: 0.6355759154747089  test: [epoch 206] loss: 0.5411231046247458        train: [epoch 207] loss: 0.6450672053465131  test: [epoch 207] loss: 0.5773621301330746        train: [epoch 208] loss: 0.6198947888552424  test: [epoch 208] loss: 0.512493120900003         train: [epoch 209] loss: 0.6333111387625355  test: [epoch 209] loss: 0.5905412067934452        train: [epoch 210] loss: 0.6380624280027698  test: [epoch 210] loss: 0.5272201578687445        train: [epoch 211] loss: 0.6251464768081749  test: [epoch 211] loss: 0.5074008821995857        train: [epoch 212] loss: 0.6159931270989072  test: [epoch 212] loss: 0.5658176821745737        train: [epoch 213] loss: 0.6195059584118091  test: [epoch 213] loss: 0.6479070385959476        train: [epoch 214] loss: 0.6187501079765932  test: [epoch 214] loss: 0.5180374926100679        train: [epoch 215] loss: 0.6196727917603     test: [epoch 215] loss: 0.5527270137601046        train: [epoch 216] loss: 0.6297416553515331  test: [epoch 216] loss: 0.6308537337250252        train: [epoch 217] loss: 0.6202821805823463  test: [epoch 217] loss: 0.5177033082171938        train: [epoch 218] loss: 0.6275064121939331  test: [epoch 218] loss: 0.518475390399735         train: [epoch 219] loss: 0.6141027857651298  test: [epoch 219] loss: 0.5505451983492599        train: [epoch 220] loss: 0.6275060454839272  test: [epoch 220] loss: 0.5575332708141603        train: [epoch 221] loss: 0.6545449227569834  test: [epoch 221] loss: 0.5523745513262246        train: [epoch 222] loss: 0.6307106731344755  test: [epoch 222] loss: 0.5162817481598717        train: [epoch 223] loss: 0.6257616538278871  test: [epoch 223] loss: 0.5754441230239948        train: [epoch 224] loss: 0.6229946781053909  test: [epoch 224] loss: 0.5702422935064836        train: [epoch 225] loss: 0.6104543674934516  test: [epoch 225] loss: 0.5122262711687863        train: [epoch 226] loss: 0.6151175229819061  test: [epoch 226] loss: 0.5263077553808796        train: [epoch 227] loss: 0.6287063187688614  test: [epoch 227] loss: 0.5458380003361603        train: [epoch 228] loss: 0.621329555191664   test: [epoch 228] loss: 0.5230312726021386        train: [epoch 229] loss: 0.6198730114073309  test: [epoch 229] loss: 0.5328692911542661        train: [epoch 230] loss: 0.6075216664613785  test: [epoch 230] loss: 0.5247692199476398        train: [epoch 231] loss: 0.630960353655874   test: [epoch 231] loss: 0.5889097307758491        train: [epoch 232] loss: 0.640873140787863   test: [epoch 232] loss: 0.5815047246967009        train: [epoch 233] loss: 0.6165949710327816  test: [epoch 233] loss: 0.5494040270720169        train: [epoch 234] loss: 0.6058261380879271  test: [epoch 234] loss: 0.5320155217366608        train: [epoch 235] loss: 0.6055252446347654  test: [epoch 235] loss: 0.5175153759687704        train: [epoch 236] loss: 0.6284664789369226  test: [epoch 236] loss: 0.6047030218647406        train: [epoch 237] loss: 0.6166705224701015  test: [epoch 237] loss: 0.5787267501781467        train: [epoch 238] loss: 0.6163711204565048  test: [epoch 238] loss: 0.5656296825022866        train: [epoch 239] loss: 0.6272195520614257  test: [epoch 239] loss: 0.567984612573718         train: [epoch 240] loss: 0.6153776398245377  test: [epoch 240] loss: 0.6530185898801404        train: [epoch 241] loss: 0.62220005533836    test: [epoch 241] loss: 0.5310337680905443        train: [epoch 242] loss: 0.6148899676672991  test: [epoch 242] loss: 0.5435276727840541        train: [epoch 243] loss: 0.6305426028953395  test: [epoch 243] loss: 0.5356479864334999        train: [epoch 244] loss: 0.6057571885060842  test: [epoch 244] loss: 0.6026558887192307        train: [epoch 245] loss: 0.6158302958661686  test: [epoch 245] loss: 0.5257233495190461        train: [epoch 246] loss: 0.6175705569943244  test: [epoch 246] loss: 0.6600966665234013        train: [epoch 247] loss: 0.6184344787207552  test: [epoch 247] loss: 0.7262871530157737        train: [epoch 248] loss: 0.5810160422525145  test: [epoch 248] loss: 0.5836344472494145        train: [epoch 249] loss: 0.6013002921731055  test: [epoch 249] loss: 0.5036008904634056        train: [epoch 250] loss: 0.6040036955446346  test: [epoch 250] loss: 0.5480003935745945        train: [epoch 251] loss: 0.6049671255147555  test: [epoch 251] loss: 0.5322032802886312        train: [epoch 252] loss: 0.6176465178027564  test: [epoch 252] loss: 0.5565938237281559        train: [epoch 253] loss: 0.5927623614015131  test: [epoch 253] loss: 0.5491165729260388        train: [epoch 254] loss: 0.6147020305718505  test: [epoch 254] loss: 0.945124683371353         train: [epoch 255] loss: 0.5940779866408133  test: [epoch 255] loss: 0.5830551741222014        train: [epoch 256] loss: 0.6014010827898565  test: [epoch 256] loss: 0.5974725997276078        train: [epoch 257] loss: 0.6204656434622625  test: [epoch 257] loss: 0.582070242296451         train: [epoch 258] loss: 0.6182731844331758  test: [epoch 258] loss: 0.535043309115458         train: [epoch 259] loss: 0.6056987070531699  test: [epoch 259] loss: 0.5863946845852028        train: [epoch 260] loss: 0.6041485551595495  test: [epoch 260] loss: 0.6039489385057017        train: [epoch 261] loss: 0.5956459561443447  test: [epoch 261] loss: 0.540342167544331         train: [epoch 262] loss: 0.6039195504971556  test: [epoch 262] loss: 0.6371298119944933        train: [epoch 263] loss: 0.5956115322271233  test: [epoch 263] loss: 0.5517927268441383        train: [epoch 264] loss: 0.594553311876571   test: [epoch 264] loss: 1.5872856166519975        train: [epoch 265] loss: 0.6064138151309378  test: [epoch 265] loss: 0.5454483392013144        train: [epoch 266] loss: 0.593294760819167   test: [epoch 266] loss: 0.5121414423412125        train: [epoch 267] loss: 0.6006469865368981  test: [epoch 267] loss: 0.5789767324227185        train: [epoch 268] loss: 0.5844997336670196  test: [epoch 268] loss: 0.6182593212028581        train: [epoch 269] loss: 0.5844244989401003  test: [epoch 269] loss: 0.608308981393988         train: [epoch 270] loss: 0.5991544983465668  test: [epoch 270] loss: 0.5463764280276489        train: [epoch 271] loss: 0.5940348892876586  test: [epoch 271] loss: 0.5743915190903719        train: [epoch 272] loss: 0.6152428428088866  test: [epoch 272] loss: 0.5472808799523123        train: [epoch 273] loss: 0.594020129662444   test: [epoch 273] loss: 0.5176874549093483        train: [epoch 274] loss: 0.5961701156566006  test: [epoch 274] loss: 0.5641826733379118        train: [epoch 275] loss: 0.588429985842529   test: [epoch 275] loss: 0.5489080256757015        train: [epoch 276] loss: 0.5963065817329097  test: [epoch 276] loss: 0.6845016896996988        train: [epoch 277] loss: 0.6013003908232872  test: [epoch 277] loss: 0.5857300104155782        train: [epoch 278] loss: 0.5943250423488045  test: [epoch 278] loss: 0.5351395782197154        train: [epoch 279] loss: 0.5919422751490221  test: [epoch 279] loss: 0.5664122898836087        train: [epoch 280] loss: 0.5911018776711007  test: [epoch 280] loss: 0.5347592432038266        train: [epoch 281] loss: 0.598933068888873   test: [epoch 281] loss: 0.5881443010876862        train: [epoch 282] loss: 0.5934461289074261  test: [epoch 282] loss: 0.6469011227231278        train: [epoch 283] loss: 0.6016135950059949  test: [epoch 283] loss: 0.6195161755594899        train: [epoch 284] loss: 0.5789976731894568  test: [epoch 284] loss: 0.6230033079107994        train: [epoch 285] loss: 0.5810626510870239  test: [epoch 285] loss: 0.5931594162037619        train: [epoch 286] loss: 0.5937911830198819  test: [epoch 286] loss: 0.5883657603307565        train: [epoch 287] loss: 0.5891866673215429  test: [epoch 287] loss: 0.5553702282365783        train: [epoch 288] loss: 0.5785654779229162  test: [epoch 288] loss: 0.5327856792602846        train: [epoch 289] loss: 0.5969249600684569  test: [epoch 289] loss: 0.5160733759816197        train: [epoch 290] loss: 0.5747251137966927  test: [epoch 290] loss: 0.5828375257757703        train: [epoch 291] loss: 0.6003068561649867  test: [epoch 291] loss: 0.7046967742196614        train: [epoch 292] loss: 0.5754458463467734  test: [epoch 292] loss: 0.5719688683390601        train: [epoch 293] loss: 0.5934988147236807  test: [epoch 293] loss: 1.9898535957284351        train: [epoch 294] loss: 0.5847497714135795  test: [epoch 294] loss: 0.5499452784967775        train: [epoch 295] loss: 0.5889788543110546  test: [epoch 295] loss: 0.5671567875488183        train: [epoch 296] loss: 0.587620064309846   test: [epoch 296] loss: 0.5585603554913781        train: [epoch 297] loss: 0.5732113142712048  test: [epoch 297] loss: 0.5645543880393319        train: [epoch 298] loss: 0.5772886986296524  test: [epoch 298] loss: 0.5574412041580671        train: [epoch 299] loss: 0.5811174091812621  test: [epoch 299] loss: 0.5317920968395482        train: [epoch 300] loss: 0.5769608680631866  test: [epoch 300] loss: 0.5238406392450369        train: [epoch 301] loss: 0.5863421821735877  test: [epoch 301] loss: 3.976118100329342         train: [epoch 302] loss: 0.5835318017563208  test: [epoch 302] loss: 0.5994203633895122        train: [epoch 303] loss: 0.5797295935496323  test: [epoch 303] loss: 0.5870977629514437        train: [epoch 304] loss: 0.5716385359660898  test: [epoch 304] loss: 0.5332372759628025        train: [epoch 305] loss: 0.588105347419043   test: [epoch 305] loss: 0.586533447595179         train: [epoch 306] loss: 0.5826037540641021  test: [epoch 306] loss: 0.5676358582653535        train: [epoch 307] loss: 0.5630798328627283  test: [epoch 307] loss: 0.5700993520168998        train: [epoch 308] loss: 0.5828180442601383  test: [epoch 308] loss: 0.5267906850784999        train: [epoch 309] loss: 0.5830624307475947  test: [epoch 309] loss: 0.5576411254963495        train: [epoch 310] loss: 0.5840383643021847  test: [epoch 310] loss: 0.5875153788510276        train: [epoch 311] loss: 0.5657671801278046  test: [epoch 311] loss: 0.5288568146319119        train: [epoch 312] loss: 0.5741962195083782  test: [epoch 312] loss: 0.5737756844362498        train: [epoch 313] loss: 0.5701673559435182  test: [epoch 313] loss: 0.51676017996734          train: [epoch 314] loss: 0.5574959490988154  test: [epoch 314] loss: 0.5108503821040338        train: [epoch 315] loss: 0.5648365801028896  test: [epoch 315] loss: 0.5339940964178802        train: [epoch 316] loss: 0.5697019917795317  test: [epoch 316] loss: 0.512426303317447         train: [epoch 317] loss: 0.567570673408258   test: [epoch 317] loss: 0.5622210672841194        train: [epoch 318] loss: 0.5660922166081467  test: [epoch 318] loss: 0.5147185935162641        train: [epoch 319] loss: 0.5607459276570677  test: [epoch 319] loss: 0.5105430160809465        train: [epoch 320] loss: 0.5607212032662912  test: [epoch 320] loss: 0.5312952826942251        train: [epoch 321] loss: 0.5666826417954373  test: [epoch 321] loss: 0.56183375079286          train: [epoch 322] loss: 0.5670351444648292  test: [epoch 322] loss: 0.5155980214713103        train: [epoch 323] loss: 0.5705850911099405  test: [epoch 323] loss: 0.5132529992237956        train: [epoch 324] loss: 0.5692345065944315  test: [epoch 324] loss: 0.5477609005088008        train: [epoch 325] loss: 0.5601217428875275  test: [epoch 325] loss: 0.5778302749149749        train: [epoch 326] loss: 0.5465357164483834  test: [epoch 326] loss: 0.5190158874534947        train: [epoch 327] loss: 0.55688374081663    test: [epoch 327] loss: 0.5473047609418951        train: [epoch 328] loss: 0.5717486622134865  test: [epoch 328] loss: 0.5598010750484282        train: [epoch 329] loss: 0.5733430401647056  test: [epoch 329] loss: 0.5529357655938069        train: [epoch 330] loss: 0.5609938688732758  test: [epoch 330] loss: 0.5174542180348439        train: [epoch 331] loss: 0.5616170833526811  test: [epoch 331] loss: 0.593763574739239         train: [epoch 332] loss: 0.5677041588631359  test: [epoch 332] loss: 0.6101551732000612        train: [epoch 333] loss: 0.5680003987470839  test: [epoch 333] loss: 0.5435658155429629        train: [epoch 334] loss: 0.5684457409219507  test: [epoch 334] loss: 0.5237813108983649        train: [epoch 335] loss: 0.5582911111939934  test: [epoch 335] loss: 0.5343623743257848        train: [epoch 336] loss: 0.5700240586325722  test: [epoch 336] loss: 0.5312333745219541        train: [epoch 337] loss: 0.5776304209962222  test: [epoch 337] loss: 0.5314980556050921        train: [epoch 338] loss: 0.5734753772136763  test: [epoch 338] loss: 0.5474723008210793        train: [epoch 339] loss: 0.5434800089270634  test: [epoch 339] loss: 0.5785139524550019        train: [epoch 340] loss: 0.550794315216881   test: [epoch 340] loss: 0.5375796190002756        train: [epoch 341] loss: 0.5539954731119894  test: [epoch 341] loss: 0.5317004060687981        train: [epoch 342] loss: 0.555360208506707   test: [epoch 342] loss: 0.5709935022357135        train: [epoch 343] loss: 0.5531678825904252  test: [epoch 343] loss: 0.5163881215391436        train: [epoch 344] loss: 0.5550996599661799  test: [epoch 344] loss: 0.5564089883652892        train: [epoch 345] loss: 0.55165983334172    test: [epoch 345] loss: 0.5752452204719538        train: [epoch 346] loss: 0.5573013928565137  test: [epoch 346] loss: 0.5204087065060841        train: [epoch 347] loss: 0.5391394903260447  test: [epoch 347] loss: 0.522033498621845         train: [epoch 348] loss: 0.5559744905895874  test: [epoch 348] loss: 0.541178609916749         train: [epoch 349] loss: 0.5495070949439348  test: [epoch 349] loss: 0.6633845233077192        train: [epoch 350] loss: 0.5513042047817753  test: [epoch 350] loss: 0.5328312573515666        train: [epoch 351] loss: 0.5446454371518835  test: [epoch 351] loss: 0.5631765934113862        train: [epoch 352] loss: 0.5301424825510731  test: [epoch 352] loss: 0.5058874366356528        train: [epoch 353] loss: 0.5532450408388842  test: [epoch 353] loss: 0.5453759731820744        train: [epoch 354] loss: 0.5472145196307784  test: [epoch 354] loss: 0.5263130972210908        train: [epoch 355] loss: 0.5451658389062706  test: [epoch 355] loss: 0.5548385340357453        train: [epoch 356] loss: 0.5581700190725462  test: [epoch 356] loss: 0.5408587293030931        train: [epoch 357] loss: 0.5552978425993162  test: [epoch 357] loss: 0.5400696403772651        train: [epoch 358] loss: 0.5552916161181505  test: [epoch 358] loss: 0.5418108558801528        train: [epoch 359] loss: 0.5491284158319694  test: [epoch 359] loss: 0.5704048917490928        train: [epoch 360] loss: 0.54430531367705    test: [epoch 360] loss: 0.5711212027967751        train: [epoch 361] loss: 0.5652582012733635  test: [epoch 361] loss: 0.622598558524099         train: [epoch 362] loss: 0.5562599814376911  test: [epoch 362] loss: 0.5853879465015542        train: [epoch 363] loss: 0.5628501977399241  test: [epoch 363] loss: 0.5699876774272221        train: [epoch 364] loss: 0.5482942041655919  test: [epoch 364] loss: 0.5110221668467411        train: [epoch 365] loss: 0.5272308100644226  test: [epoch 365] loss: 0.5629206165635392        train: [epoch 366] loss: 0.5364329673369673  test: [epoch 366] loss: 0.543829048426512         train: [epoch 367] loss: 0.5337973379432543  test: [epoch 367] loss: 0.5543667925205171        train: [epoch 368] loss: 0.5553551081804959  test: [epoch 368] loss: 0.5286413998656341        train: [epoch 369] loss: 0.5482962506535941  test: [epoch 369] loss: 0.5303152845892355        train: [epoch 370] loss: 0.5325269867240001  test: [epoch 370] loss: 0.519672201167494         train: [epoch 371] loss: 0.5240854308844536  test: [epoch 371] loss: 0.5239589473041536        train: [epoch 372] loss: 0.5354184514130619  test: [epoch 372] loss: 0.6273414934924384        train: [epoch 373] loss: 0.5354739546783533  test: [epoch 373] loss: 0.5247719830032918        train: [epoch 374] loss: 0.5333832351852901  test: [epoch 374] loss: 0.5167830704418245        train: [epoch 375] loss: 0.5286920865023886  test: [epoch 375] loss: 0.5786220433686345        train: [epoch 376] loss: 0.5311403892564527  test: [epoch 376] loss: 0.5542170768070642        train: [epoch 377] loss: 0.5461135222099119  test: [epoch 377] loss: 0.6311398141609356        train: [epoch 378] loss: 0.5348377259874003  test: [epoch 378] loss: 0.5468111159875995        train: [epoch 379] loss: 0.529374156036684   test: [epoch 379] loss: 0.5251755178819462        train: [epoch 380] loss: 0.5358663690449155  test: [epoch 380] loss: 0.5882988324945795        train: [epoch 381] loss: 0.5280156131823265  test: [epoch 381] loss: 0.5163454677516449        train: [epoch 382] loss: 0.5200942178534866  test: [epoch 382] loss: 0.5884122248791311        train: [epoch 383] loss: 0.531090592792146   test: [epoch 383] loss: 0.5685614439477911        train: [epoch 384] loss: 0.5312572801873345  test: [epoch 384] loss: 0.580046042706233         train: [epoch 385] loss: 0.5574402526957197  test: [epoch 385] loss: 0.5072437100692576        train: [epoch 386] loss: 0.5350849112761552  test: [epoch 386] loss: 0.6129218869035451        train: [epoch 387] loss: 0.5684005647336495  test: [epoch 387] loss: 0.5363241901607062        train: [epoch 388] loss: 0.5480276789055604  test: [epoch 388] loss: 0.5174581859754974        train: [epoch 389] loss: 0.5327273235796185  test: [epoch 389] loss: 0.5284916993818916        train: [epoch 390] loss: 0.5413944331220198  test: [epoch 390] loss: 0.5483446139209318        train: [epoch 391] loss: 0.5476496667319989  test: [epoch 391] loss: 0.6149181235149938        train: [epoch 392] loss: 0.5522808050246638  test: [epoch 392] loss: 0.5447150224809919        train: [epoch 393] loss: 0.5130747051984248  test: [epoch 393] loss: 0.5388958776043394        train: [epoch 394] loss: 0.5233769179961688  test: [epoch 394] loss: 0.5660296940027149        train: [epoch 395] loss: 0.5115396812516366  test: [epoch 395] loss: 0.5166954839508174        train: [epoch 396] loss: 0.5246473110992919  test: [epoch 396] loss: 0.5330356864821133        train: [epoch 397] loss: 0.5358786120095964  test: [epoch 397] loss: 0.5352810371049984        train: [epoch 398] loss: 0.5254458637199493  test: [epoch 398] loss: 0.5775247756070565        train: [epoch 399] loss: 0.5148798246729075  test: [epoch 399] loss: 0.5535115652017434        train: [epoch 400] loss: 0.5271818999513547  test: [epoch 400] loss: 0.5390495711417512        train: [epoch 401] loss: 0.5289432423340185  test: [epoch 401] loss: 0.5221609680064269        train: [epoch 402] loss: 0.5338665931555172  test: [epoch 402] loss: 0.5381350046401301        train: [epoch 403] loss: 0.5366279040253402  test: [epoch 403] loss: 0.5905974308995752        train: [epoch 404] loss: 0.5182071182113966  test: [epoch 404] loss: 0.5228896747480897        train: [epoch 405] loss: 0.5259061413405961  test: [epoch 405] loss: 0.5825543711810519        train: [epoch 406] loss: 0.5230654268441779  test: [epoch 406] loss: 0.5469770226669332        train: [epoch 407] loss: 0.5364199956620014  test: [epoch 407] loss: 0.5197174233806621        train: [epoch 408] loss: 0.5327643691640035  test: [epoch 408] loss: 0.5423091358348849        train: [epoch 409] loss: 0.522642133986072   test: [epoch 409] loss: 0.5807144239019199        train: [epoch 410] loss: 0.5299115627956132  test: [epoch 410] loss: 0.5339315854523169        train: [epoch 411] loss: 0.512659854514265   test: [epoch 411] loss: 0.5441012243941492        train: [epoch 412] loss: 0.5148571924747943  test: [epoch 412] loss: 0.6149020003359913        train: [epoch 413] loss: 0.5104423453781425  test: [epoch 413] loss: 0.5247613508005384        train: [epoch 414] loss: 0.5179025916001216  test: [epoch 414] loss: 0.55822767533769          train: [epoch 415] loss: 0.5165444522577197  test: [epoch 415] loss: 0.5639301521187154        train: [epoch 416] loss: 0.5204135567015779  test: [epoch 416] loss: 0.5387725122399971        train: [epoch 417] loss: 0.517473542745654   test: [epoch 417] loss: 0.5622374301200788        train: [epoch 418] loss: 0.5133826209311464  test: [epoch 418] loss: 0.5851116351353803        train: [epoch 419] loss: 0.5146986927654618  test: [epoch 419] loss: 0.5386837470141174        train: [epoch 420] loss: 0.5259156991804133  test: [epoch 420] loss: 0.5244197856658726        train: [epoch 421] loss: 0.5330422071388513  test: [epoch 421] loss: 0.5259865261059611        train: [epoch 422] loss: 0.50522048002474    test: [epoch 422] loss: 0.5578033285303461        train: [epoch 423] loss: 0.5229719930573548  test: [epoch 423] loss: 0.5309179343480461        train: [epoch 424] loss: 0.5073597602343239  test: [epoch 424] loss: 0.539933086532            train: [epoch 425] loss: 0.49782597779466337 test: [epoch 425] loss: 0.5154712351697037        train: [epoch 426] loss: 0.5158725118815111  test: [epoch 426] loss: 0.5658877406129729        train: [epoch 427] loss: 0.5131973214196806  test: [epoch 427] loss: 0.5446739443414358        train: [epoch 428] loss: 0.497684903443378   test: [epoch 428] loss: 0.5206982998608136        train: [epoch 429] loss: 0.5120360279387712  test: [epoch 429] loss: 0.6236883031207069        train: [epoch 430] loss: 0.5406699519401471  test: [epoch 430] loss: 0.5193983360713155        train: [epoch 431] loss: 0.5278330487236791  test: [epoch 431] loss: 0.5661879838413243        train: [epoch 432] loss: 0.5286080629572494  test: [epoch 432] loss: 0.5433224750478506        train: [epoch 433] loss: 0.5087719063055228  test: [epoch 433] loss: 0.552631061631567         train: [epoch 434] loss: 0.5068980694156313  test: [epoch 434] loss: 0.5389720109389293        train: [epoch 435] loss: 0.5020730480560399  test: [epoch 435] loss: 0.5418020339318153        train: [epoch 436] loss: 0.5236608321697096  test: [epoch 436] loss: 0.5116553214763151        train: [epoch 437] loss: 0.5154078598302806  test: [epoch 437] loss: 0.5551927007216454        train: [epoch 438] loss: 0.49650054086121315 test: [epoch 438] loss: 0.5628149332633509        train: [epoch 439] loss: 0.5058735696112964  test: [epoch 439] loss: 0.542687672283972         train: [epoch 440] loss: 0.5019061758183397  test: [epoch 440] loss: 0.5577068941504788        train: [epoch 441] loss: 0.5105991652231916  test: [epoch 441] loss: 0.5734112905352472        train: [epoch 442] loss: 0.5026730142786865  test: [epoch 442] loss: 0.555599971233378         train: [epoch 443] loss: 0.5103415825443076  test: [epoch 443] loss: 0.5431621245499917        train: [epoch 444] loss: 0.4994286568221342  test: [epoch 444] loss: 0.529174559567734         train: [epoch 445] loss: 0.5044031252661546  test: [epoch 445] loss: 0.5581591323254099        train: [epoch 446] loss: 0.5080369107111103  test: [epoch 446] loss: 0.5328130881184874        train: [epoch 447] loss: 0.494483871349186   test: [epoch 447] loss: 0.5241127195580455        train: [epoch 448] loss: 0.5063249059054706  test: [epoch 448] loss: 0.5258546791399168        train: [epoch 449] loss: 0.4984802907534117  test: [epoch 449] loss: 0.5486426110235972        train: [epoch 450] loss: 0.4950414523283569  test: [epoch 450] loss: 0.5211540550538016        train: [epoch 451] loss: 0.49694199109251913 test: [epoch 451] loss: 0.5401685261687608        train: [epoch 452] loss: 0.49036699970220904 test: [epoch 452] loss: 0.5332403232912358        train: [epoch 453] loss: 0.5054859752922239  test: [epoch 453] loss: 0.5564346927694328        train: [epoch 454] loss: 0.4939852446512609  test: [epoch 454] loss: 0.5284748746948181        train: [epoch 455] loss: 0.5017675218418282  test: [epoch 455] loss: 0.5340521825032085        train: [epoch 456] loss: 0.4949956691953215  test: [epoch 456] loss: 0.5322105931957746        train: [epoch 457] loss: 0.5032187021822645  test: [epoch 457] loss: 0.5199041611742657        train: [epoch 458] loss: 0.5222215622729135  test: [epoch 458] loss: 0.5284880043961154        train: [epoch 459] loss: 0.4973674888417516  test: [epoch 459] loss: 0.555365475248434         train: [epoch 460] loss: 0.48677197089826013 test: [epoch 460] loss: 0.5807809796646024        train: [epoch 461] loss: 0.4864859208736539  test: [epoch 461] loss: 0.5412488033309553        train: [epoch 462] loss: 0.503259400063287   test: [epoch 462] loss: 0.6145835018866611        train: [epoch 463] loss: 0.48913476352960006 test: [epoch 463] loss: 0.5287480658508378        train: [epoch 464] loss: 0.4911051413682165  test: [epoch 464] loss: 0.5297715130504208        train: [epoch 465] loss: 0.5171514688422237  test: [epoch 465] loss: 0.5404788913025897        train: [epoch 466] loss: 0.49175495927718993 test: [epoch 466] loss: 0.5935767910387835        train: [epoch 467] loss: 0.5085503937210335  test: [epoch 467] loss: 0.5384804617377806        train: [epoch 468] loss: 0.47994164461325156 test: [epoch 468] loss: 0.5456588618486911        train: [epoch 469] loss: 0.5005148509904754  test: [epoch 469] loss: 0.5313181433018941        train: [epoch 470] loss: 0.4869895991272377  test: [epoch 470] loss: 0.5761276100579125        train: [epoch 471] loss: 0.4917008610381934  test: [epoch 471] loss: 0.5261861125287458        train: [epoch 472] loss: 0.49001369461019545 test: [epoch 472] loss: 0.5316880825431545        train: [epoch 473] loss: 0.5052582097304861  test: [epoch 473] loss: 0.5280475763733796        train: [epoch 474] loss: 0.4779960339467309  test: [epoch 474] loss: 0.5265733222454299        train: [epoch 475] loss: 0.4838589551988798  test: [epoch 475] loss: 0.520853413188435         train: [epoch 476] loss: 0.48874642680612596 test: [epoch 476] loss: 0.5499073666066909        train: [epoch 477] loss: 0.48471413416641834 test: [epoch 477] loss: 0.5642590310850112        train: [epoch 478] loss: 0.47400266315877293 test: [epoch 478] loss: 0.5564855373410833        train: [epoch 479] loss: 0.48234506166754837 test: [epoch 479] loss: 0.5375488162964958        train: [epoch 480] loss: 0.47953501258749287 test: [epoch 480] loss: 0.5254887984594615        train: [epoch 481] loss: 0.4845734811916216  test: [epoch 481] loss: 0.5397902315800145        train: [epoch 482] loss: 0.4726618123037206  test: [epoch 482] loss: 0.5416211462994943        train: [epoch 483] loss: 0.4778187320662662  test: [epoch 483] loss: 0.5723854759917087        train: [epoch 484] loss: 0.4815006403610857  test: [epoch 484] loss: 0.5584255759600544        train: [epoch 485] loss: 0.4889044571186368  test: [epoch 485] loss: 0.599718027550918         train: [epoch 486] loss: 0.48910005573713355 test: [epoch 486] loss: 0.5401372291638304        train: [epoch 487] loss: 0.48919049474869136 test: [epoch 487] loss: 0.5243389954988801        train: [epoch 488] loss: 0.4998093163540183  test: [epoch 488] loss: 0.5606675229722273        train: [epoch 489] loss: 0.48057621211955737 test: [epoch 489] loss: 0.5305631176959669        train: [epoch 490] loss: 0.46351875837092443 test: [epoch 490] loss: 0.5447771799863356        train: [epoch 491] loss: 0.48505999255427634 test: [epoch 491] loss: 0.5588727367182514        train: [epoch 492] loss: 0.493069410307862   test: [epoch 492] loss: 0.5443097554945348        train: [epoch 493] loss: 0.4565221311851283  test: [epoch 493] loss: 0.5283329148505109        train: [epoch 494] loss: 0.49922245811490235 test: [epoch 494] loss: 0.5472368530552949        train: [epoch 495] loss: 0.46113743793552525 test: [epoch 495] loss: 0.5491859749005259        train: [epoch 496] loss: 0.4862119985520217  test: [epoch 496] loss: 0.5439334008965113        train: [epoch 497] loss: 0.49755260102540666 test: [epoch 497] loss: 0.5199363345113477        train: [epoch 498] loss: 0.48322827376714894 test: [epoch 498] loss: 0.5441473081285708        train: [epoch 499] loss: 0.4809363765276126  test: [epoch 499] loss: 0.5147310981379907        train: [epoch 500] loss: 0.4785475802279587  test: [epoch 500] loss: 0.5789637504185109        train: [epoch 501] loss: 0.4720682558440316  test: [epoch 501] loss: 0.5460188382922647        train: [epoch 502] loss: 0.4881200932625359  test: [epoch 502] loss: 0.553620173222111         train: [epoch 503] loss: 0.4867591025704028  test: [epoch 503] loss: 0.5489318525427658        train: [epoch 504] loss: 0.48209915802639464 test: [epoch 504] loss: 0.5373395620114748        train: [epoch 505] loss: 0.4684687071167214  test: [epoch 505] loss: 0.5297827720299167        train: [epoch 506] loss: 0.47815372574818005 test: [epoch 506] loss: 0.5256785581750641        train: [epoch 507] loss: 0.47528328978202455 test: [epoch 507] loss: 0.5127519095231666        train: [epoch 508] loss: 0.4821579986630003  test: [epoch 508] loss: 0.5181916402956603        train: [epoch 509] loss: 0.478794103570459   test: [epoch 509] loss: 0.5365971996835415        train: [epoch 510] loss: 0.48396604339952115 test: [epoch 510] loss: 0.5505794609055255        train: [epoch 511] loss: 0.4687418417901571  test: [epoch 511] loss: 0.5454347142982686        train: [epoch 512] loss: 0.4682700381981598  test: [epoch 512] loss: 0.5565633416508988        train: [epoch 513] loss: 0.4945778610184068  test: [epoch 513] loss: 0.5328609942486415        train: [epoch 514] loss: 0.4707346556787438  test: [epoch 514] loss: 0.554494056196641         train: [epoch 515] loss: 0.483031592345032   test: [epoch 515] loss: 0.5378883802769202        train: [epoch 516] loss: 0.4881174079979191  test: [epoch 516] loss: 0.5665555821906906        train: [epoch 517] loss: 0.4624620853401485  test: [epoch 517] loss: 0.5349316772049192        train: [epoch 518] loss: 0.4748891579994451  test: [epoch 518] loss: 0.544705973431585         train: [epoch 519] loss: 0.48561405009371816 test: [epoch 519] loss: 0.5271385794092642        train: [epoch 520] loss: 0.4545770174177353  test: [epoch 520] loss: 0.5611327618623184        train: [epoch 521] loss: 0.4531292579483514  test: [epoch 521] loss: 0.5164538870855148        train: [epoch 522] loss: 0.4748564303080782  test: [epoch 522] loss: 0.5495566157596132        train: [epoch 523] loss: 0.4592143371498753  test: [epoch 523] loss: 0.5240190318304911        train: [epoch 524] loss: 0.48798850712930486 test: [epoch 524] loss: 0.5277177811460008        train: [epoch 525] loss: 0.47656907979122876 test: [epoch 525] loss: 0.5836844841819402        train: [epoch 526] loss: 0.47142035740959914 test: [epoch 526] loss: 0.5465958950839525        train: [epoch 527] loss: 0.4600887436478526  test: [epoch 527] loss: 0.530070022921031         train: [epoch 528] loss: 0.4585486516523798  test: [epoch 528] loss: 0.554328886424132         train: [epoch 529] loss: 0.4867032839291747  test: [epoch 529] loss: 0.5361110215078464        train: [epoch 530] loss: 0.4591721424015648  test: [epoch 530] loss: 0.5431778190919471        train: [epoch 531] loss: 0.47498497954319446 test: [epoch 531] loss: 0.5582097676323208        train: [epoch 532] loss: 0.4701642551212455  test: [epoch 532] loss: 0.5180731067188605        train: [epoch 533] loss: 0.4838999159189749  test: [epoch 533] loss: 0.526249869260027         train: [epoch 534] loss: 0.4533657308487438  test: [epoch 534] loss: 0.5295336463898075        train: [epoch 535] loss: 0.4642288608614985  test: [epoch 535] loss: 0.5200344917432131        train: [epoch 536] loss: 0.47740827150435183 test: [epoch 536] loss: 0.5376877195879404        train: [epoch 537] loss: 0.4663176036539012  test: [epoch 537] loss: 0.5335401756248901        train: [epoch 538] loss: 0.46301981855441    test: [epoch 538] loss: 0.5441253076875885        train: [epoch 539] loss: 0.4725794024897153  test: [epoch 539] loss: 0.5430211838632181        train: [epoch 540] loss: 0.4562015042058554  test: [epoch 540] loss: 0.5634413602402295        train: [epoch 541] loss: 0.46035962916998874 test: [epoch 541] loss: 0.5442776549797261        train: [epoch 542] loss: 0.44785373940475953 test: [epoch 542] loss: 0.5375442007311753        train: [epoch 543] loss: 0.4681202465104069  test: [epoch 543] loss: 0.5531871157957463        train: [epoch 544] loss: 0.46920434571855507 test: [epoch 544] loss: 0.52177241951201          train: [epoch 545] loss: 0.4728398677708512  test: [epoch 545] loss: 0.5229869301276382        train: [epoch 546] loss: 0.47814071012887355 test: [epoch 546] loss: 0.526369697056487         train: [epoch 547] loss: 0.46759134063668456 test: [epoch 547] loss: 0.5321022977547893        train: [epoch 548] loss: 0.478045325074778   test: [epoch 548] loss: 0.5266098568894603        train: [epoch 549] loss: 0.4637674770628787  test: [epoch 549] loss: 0.5403947970446197        train: [epoch 550] loss: 0.45735465401054504 test: [epoch 550] loss: 0.5521052133052332        train: [epoch 551] loss: 0.45384332512132824 test: [epoch 551] loss: 0.5191426208652234        train: [epoch 552] loss: 0.4433808443035821  test: [epoch 552] loss: 0.5403754977816967        train: [epoch 553] loss: 0.4764345925049071  test: [epoch 553] loss: 0.528825934270371         train: [epoch 554] loss: 0.46098220765431297 test: [epoch 554] loss: 0.5470257621333267        train: [epoch 555] loss: 0.45578769060881935 test: [epoch 555] loss: 0.5435714697578815        train: [epoch 556] loss: 0.4562821900475042  test: [epoch 556] loss: 0.5364583873154497        train: [epoch 557] loss: 0.46128425141871343 test: [epoch 557] loss: 0.5478858548716523        train: [epoch 558] loss: 0.446151381786471   test: [epoch 558] loss: 0.5299324541598787        train: [epoch 559] loss: 0.45927802920575717 test: [epoch 559] loss: 0.5934928727361682        train: [epoch 560] loss: 0.46299723949646215 test: [epoch 560] loss: 0.5279351267672526        train: [epoch 561] loss: 0.4574186265622302  test: [epoch 561] loss: 0.5343400724077068        train: [epoch 562] loss: 0.4520012209350948  test: [epoch 562] loss: 0.5174848911928872        train: [epoch 563] loss: 0.4655621931919368  test: [epoch 563] loss: 0.5287314055165504        train: [epoch 564] loss: 0.45126466500833473 test: [epoch 564] loss: 0.5180628557448481        train: [epoch 565] loss: 0.46026530072248806 test: [epoch 565] loss: 0.5337887121138009        train: [epoch 566] loss: 0.44443268546291814 test: [epoch 566] loss: 0.5276836021253436        train: [epoch 567] loss: 0.44556192700640906 test: [epoch 567] loss: 0.5396431673923943        train: [epoch 568] loss: 0.45903631198879347 test: [epoch 568] loss: 0.5270891814603555        train: [epoch 569] loss: 0.4602805217859323  test: [epoch 569] loss: 0.5266880368830922        train: [epoch 570] loss: 0.4695062743128546  test: [epoch 570] loss: 0.5788584468681451        train: [epoch 571] loss: 0.45172067718728026 test: [epoch 571] loss: 0.5374875365379704        train: [epoch 572] loss: 0.43646176373614126 test: [epoch 572] loss: 0.551764420170386         train: [epoch 573] loss: 0.45917583839376935 test: [epoch 573] loss: 0.5247654308024762        train: [epoch 574] loss: 0.45108277089982324 test: [epoch 574] loss: 0.559142218086875         train: [epoch 575] loss: 0.47129590941758903 test: [epoch 575] loss: 0.5372826642699778        train: [epoch 576] loss: 0.46415851783578604 test: [epoch 576] loss: 0.5331270061666564        train: [epoch 577] loss: 0.44938664376986454 test: [epoch 577] loss: 0.5375790752790807        train: [epoch 578] loss: 0.4589535658061944  test: [epoch 578] loss: 0.5411091846143561        train: [epoch 579] loss: 0.44795529150981367 test: [epoch 579] loss: 0.5571589574040179        train: [epoch 580] loss: 0.4617719475607841  test: [epoch 580] loss: 0.5244195145421685        train: [epoch 581] loss: 0.45542592105210916 test: [epoch 581] loss: 0.5425689687888028        train: [epoch 582] loss: 0.44314957471831556 test: [epoch 582] loss: 0.5185757712630062        train: [epoch 583] loss: 0.4463355311901955  test: [epoch 583] loss: 0.5295416733036952        train: [epoch 584] loss: 0.45941320389154744 test: [epoch 584] loss: 0.5335084703976378        train: [epoch 585] loss: 0.44632403567790563 test: [epoch 585] loss: 0.5157787703501572        train: [epoch 586] loss: 0.4461195569268093  test: [epoch 586] loss: 0.5422322798671912        train: [epoch 587] loss: 0.4478940732872438  test: [epoch 587] loss: 0.6251393235199231        train: [epoch 588] loss: 0.44713248743754114 test: [epoch 588] loss: 0.5466781503182301        train: [epoch 589] loss: 0.4624474878266103  test: [epoch 589] loss: 0.5654053039528029        train: [epoch 590] loss: 0.4452925686860458  test: [epoch 590] loss: 0.5755300706187845        train: [epoch 591] loss: 0.44627244212751227 test: [epoch 591] loss: 0.5209706389232024        train: [epoch 592] loss: 0.4695818869852658  test: [epoch 592] loss: 0.5314621770617003        train: [epoch 593] loss: 0.4617533356537435  test: [epoch 593] loss: 0.5388725324393813        train: [epoch 594] loss: 0.45188913817258186 test: [epoch 594] loss: 0.5491484270673175        train: [epoch 595] loss: 0.4434146998909841  test: [epoch 595] loss: 0.529216876773301         train: [epoch 596] loss: 0.44473745005627496 test: [epoch 596] loss: 0.5808954112786106        train: [epoch 597] loss: 0.4538254021742622  test: [epoch 597] loss: 0.5509595566552654        train: [epoch 598] loss: 0.4366186695062103  test: [epoch 598] loss: 0.5323230797502551        train: [epoch 599] loss: 0.44819191959290294 test: [epoch 599] loss: 0.5281187498456953        train: [epoch 600] loss: 0.460052603878738   test: [epoch 600] loss: 0.5354598041131308        train: [epoch 601] loss: 0.44428322056601255 test: [epoch 601] loss: 0.5254837712580759        train: [epoch 602] loss: 0.4403868507615663  test: [epoch 602] loss: 0.5248055403779569        train: [epoch 603] loss: 0.43085796650598535 test: [epoch 603] loss: 0.5391313011172368        train: [epoch 604] loss: 0.45130868569849764 test: [epoch 604] loss: 0.6263437908609842        train: [epoch 605] loss: 0.436759855235539   test: [epoch 605] loss: 0.5372946971389422        train: [epoch 606] loss: 0.4435950564631931  test: [epoch 606] loss: 0.5414355041458426        train: [epoch 607] loss: 0.44672585772056145 test: [epoch 607] loss: 0.5402367825775773        train: [epoch 608] loss: 0.4333828611147967  test: [epoch 608] loss: 0.5938117080710649        train: [epoch 609] loss: 0.4402536014629373  test: [epoch 609] loss: 0.5421592068133583        train: [epoch 610] loss: 0.4409627195913502  test: [epoch 610] loss: 0.5322024219696811        train: [epoch 611] loss: 0.45167913894700173 test: [epoch 611] loss: 0.5559796490529904        train: [epoch 612] loss: 0.45319399664916976 test: [epoch 612] loss: 0.5616846387954934        train: [epoch 613] loss: 0.43640750065673406 test: [epoch 613] loss: 0.516539508187872         train: [epoch 614] loss: 0.44505481641518363 test: [epoch 614] loss: 0.6064523976339122        train: [epoch 615] loss: 0.44709718252608777 test: [epoch 615] loss: 0.5330012468276791        train: [epoch 616] loss: 0.44098681844777093 test: [epoch 616] loss: 0.5146497699367534        train: [epoch 617] loss: 0.4294082837647892  test: [epoch 617] loss: 0.5222364328495197        train: [epoch 618] loss: 0.434703768481892   test: [epoch 618] loss: 0.5346233125394777        train: [epoch 619] loss: 0.45156910352446844 test: [epoch 619] loss: 0.5589997844451219        train: [epoch 620] loss: 0.461797452301742   test: [epoch 620] loss: 0.555059003972526         train: [epoch 621] loss: 0.44133408460995016 test: [epoch 621] loss: 0.5338730830579416        train: [epoch 622] loss: 0.4539417734180067  test: [epoch 622] loss: 0.5822381306489168        train: [epoch 623] loss: 0.44658288269793855 test: [epoch 623] loss: 0.5656628088227201        train: [epoch 624] loss: 0.4332145063585186  test: [epoch 624] loss: 0.5296038608222435        train: [epoch 625] loss: 0.44205153755936016 test: [epoch 625] loss: 0.5342058299374812        train: [epoch 626] loss: 0.42706104518212173 test: [epoch 626] loss: 0.5936237506003725        train: [epoch 627] loss: 0.4278493933947192  test: [epoch 627] loss: 0.5401250972109393        train: [epoch 628] loss: 0.4579988901683281  test: [epoch 628] loss: 0.5211128980549244        train: [epoch 629] loss: 0.4645766747763933  test: [epoch 629] loss: 0.5189871710573323        train: [epoch 630] loss: 0.4277489772220065  test: [epoch 630] loss: 0.534798223305522         train: [epoch 631] loss: 0.4181597651014095  test: [epoch 631] loss: 0.529816604657833         train: [epoch 632] loss: 0.43748887121808616 test: [epoch 632] loss: 0.5256119914635269        train: [epoch 633] loss: 0.4336413561556996  test: [epoch 633] loss: 0.5437537162787759        train: [epoch 634] loss: 0.4455410969253703  test: [epoch 634] loss: 0.5278752608355137        train: [epoch 635] loss: 0.4429116381278131  test: [epoch 635] loss: 0.5323498428367017        train: [epoch 636] loss: 0.4426592403174091  test: [epoch 636] loss: 0.5252118191035835        train: [epoch 637] loss: 0.4455089104583842  test: [epoch 637] loss: 0.5360044025642515        train: [epoch 638] loss: 0.43729024172500347 test: [epoch 638] loss: 0.5388152489798274        train: [epoch 639] loss: 0.4437345551874455  test: [epoch 639] loss: 0.556801780776758         train: [epoch 640] loss: 0.4430661419289056  test: [epoch 640] loss: 0.5525823410135186        train: [epoch 641] loss: 0.43882440531688993 test: [epoch 641] loss: 0.5367659613739575        train: [epoch 642] loss: 0.4402968015103493  test: [epoch 642] loss: 0.5480231427337822        train: [epoch 643] loss: 0.43110680450001476 test: [epoch 643] loss: 0.5284572105346439        train: [epoch 644] loss: 0.42726976327029165 test: [epoch 644] loss: 0.5368248940251017        train: [epoch 645] loss: 0.4382581696117528  test: [epoch 645] loss: 0.5224609671180114        train: [epoch 646] loss: 0.4311118218516871  test: [epoch 646] loss: 0.5598822282926579        train: [epoch 647] loss: 0.41484125865083205 test: [epoch 647] loss: 0.531861764531156         train: [epoch 648] loss: 0.4178207825410833  test: [epoch 648] loss: 0.5401698660944587        train: [epoch 649] loss: 0.4323407118393162  test: [epoch 649] loss: 0.527605284196106         train: [epoch 650] loss: 0.4560627395533744  test: [epoch 650] loss: 0.5311357499434415        train: [epoch 651] loss: 0.41552676759798407 test: [epoch 651] loss: 0.5514572934463913        train: [epoch 652] loss: 0.4323560569910239  test: [epoch 652] loss: 0.5239260091177169        train: [epoch 653] loss: 0.4199630887036278  test: [epoch 653] loss: 0.5266053477560964        train: [epoch 654] loss: 0.4280663282177901  test: [epoch 654] loss: 0.5396334697106552        train: [epoch 655] loss: 0.43970771024900357 test: [epoch 655] loss: 0.5287563731758604        train: [epoch 656] loss: 0.4194099805820067  test: [epoch 656] loss: 0.5628816949581185        train: [epoch 657] loss: 0.43154310531341245 test: [epoch 657] loss: 0.535311198940544         train: [epoch 658] loss: 0.4188939572316413  test: [epoch 658] loss: 0.5226345560938056        train: [epoch 659] loss: 0.4122771642696273  test: [epoch 659] loss: 0.5258861882309537        train: [epoch 660] loss: 0.4378617674983731  test: [epoch 660] loss: 0.5282005836897525        train: [epoch 661] loss: 0.4390646494255661  test: [epoch 661] loss: 0.5258910535198101        train: [epoch 662] loss: 0.4370130980201527  test: [epoch 662] loss: 0.5404161330993564        train: [epoch 663] loss: 0.423650229024302   test: [epoch 663] loss: 0.5251958969084173        train: [epoch 664] loss: 0.4246906544374841  test: [epoch 664] loss: 0.526522632918584         train: [epoch 665] loss: 0.42373983907057766 test: [epoch 665] loss: 0.5483721314220926        train: [epoch 666] loss: 0.4317548616739552  test: [epoch 666] loss: 0.5308380799698561        train: [epoch 667] loss: 0.42900578648041154 test: [epoch 667] loss: 0.5646296019586929        train: [epoch 668] loss: 0.44357765061507715 test: [epoch 668] loss: 0.5198271618608526        train: [epoch 669] loss: 0.413544696857243   test: [epoch 669] loss: 0.5311667448073385        train: [epoch 670] loss: 0.43420035258221323 test: [epoch 670] loss: 0.5207788800451507        train: [epoch 671] loss: 0.42597690462025056 test: [epoch 671] loss: 0.5192444177439046        train: [epoch 672] loss: 0.43037409577443486 test: [epoch 672] loss: 0.5435266881430036        train: [epoch 673] loss: 0.43739103798334344 test: [epoch 673] loss: 0.5430479024407876        train: [epoch 674] loss: 0.4324445113353613  test: [epoch 674] loss: 0.5456967563670404        train: [epoch 675] loss: 0.41829660997073137 test: [epoch 675] loss: 0.5302516497778           train: [epoch 676] loss: 0.4205625587351547  test: [epoch 676] loss: 0.5211236574275367        train: [epoch 677] loss: 0.4311152010452322  test: [epoch 677] loss: 0.5197081289191621        train: [epoch 678] loss: 0.41430954315720586 test: [epoch 678] loss: 0.5496440156408914        train: [epoch 679] loss: 0.42563587673214504 test: [epoch 679] loss: 0.5417036127801186        train: [epoch 680] loss: 0.43681796029984343 test: [epoch 680] loss: 0.5408216298067955        train: [epoch 681] loss: 0.4211059286604881  test: [epoch 681] loss: 0.5229200654855268        train: [epoch 682] loss: 0.4350694665970871  test: [epoch 682] loss: 0.5369358092067519        train: [epoch 683] loss: 0.4184903231091926  test: [epoch 683] loss: 0.5279306377383913        train: [epoch 684] loss: 0.42437458171464887 test: [epoch 684] loss: 0.5355666183102467        train: [epoch 685] loss: 0.4316851959065066  test: [epoch 685] loss: 0.5385893906850081        train: [epoch 686] loss: 0.41853284849330064 test: [epoch 686] loss: 0.5254494122685098        train: [epoch 687] loss: 0.42676324646077524 test: [epoch 687] loss: 0.5344560864163469        train: [epoch 688] loss: 0.4075228815016769  test: [epoch 688] loss: 0.526192370651492         train: [epoch 689] loss: 0.4494584273764166  test: [epoch 689] loss: 0.5194788868321296        train: [epoch 690] loss: 0.4133939672077192  test: [epoch 690] loss: 0.51942137984676          train: [epoch 691] loss: 0.4219830593218656  test: [epoch 691] loss: 0.5494651273290361        train: [epoch 692] loss: 0.40524711717662026 test: [epoch 692] loss: 0.5211507691502852        train: [epoch 693] loss: 0.4066048150290554  test: [epoch 693] loss: 0.5496620413548088        train: [epoch 694] loss: 0.40699417077388916 test: [epoch 694] loss: 0.5283371486705553        train: [epoch 695] loss: 0.41848612445425826 test: [epoch 695] loss: 0.5241196966405232        train: [epoch 696] loss: 0.42995192642648    test: [epoch 696] loss: 0.53051144538899          train: [epoch 697] loss: 0.4443624534364696  test: [epoch 697] loss: 0.5233172280738557        train: [epoch 698] loss: 0.40628331489486713 test: [epoch 698] loss: 0.5403320817518664        train: [epoch 699] loss: 0.4056428156746787  test: [epoch 699] loss: 0.5299901669686505        train: [epoch 700] loss: 0.4365284349992212  test: [epoch 700] loss: 0.5258890105607293        train: [epoch 701] loss: 0.41236030332392665 test: [epoch 701] loss: 0.5210429461625058        train: [epoch 702] loss: 0.4293830773006246  test: [epoch 702] loss: 0.5131375700794505        train: [epoch 703] loss: 0.4307853368186563  test: [epoch 703] loss: 0.5208151014291306        train: [epoch 704] loss: 0.4164535113648574  test: [epoch 704] loss: 0.5244696218678117        train: [epoch 705] loss: 0.42059331532174454 test: [epoch 705] loss: 0.5227718161279094        train: [epoch 706] loss: 0.4047582879470993  test: [epoch 706] loss: 0.5085680386142133        train: [epoch 707] loss: 0.43162545707536626 test: [epoch 707] loss: 0.5172537588620524        train: [epoch 708] loss: 0.412867800340951   test: [epoch 708] loss: 0.5210173933130472        train: [epoch 709] loss: 0.4032331908497257  test: [epoch 709] loss: 0.550753731661412         train: [epoch 710] loss: 0.40438517060229234 test: [epoch 710] loss: 0.5264888508238865        train: [epoch 711] loss: 0.403177592028363   test: [epoch 711] loss: 0.5344747736646697        train: [epoch 712] loss: 0.4206368889351167  test: [epoch 712] loss: 0.5600759022060146        train: [epoch 713] loss: 0.42569768048192264 test: [epoch 713] loss: 0.5238517985729407        train: [epoch 714] loss: 0.40796399754663    test: [epoch 714] loss: 0.5374144942554676        train: [epoch 715] loss: 0.4161039528025779  test: [epoch 715] loss: 0.5413083101854541        train: [epoch 716] loss: 0.41758791713486304 test: [epoch 716] loss: 0.598024043116819         train: [epoch 717] loss: 0.418420909646732   test: [epoch 717] loss: 0.5257803306300396        train: [epoch 718] loss: 0.43940288399974087 test: [epoch 718] loss: 0.5501947962877729        train: [epoch 719] loss: 0.4292194177180183  test: [epoch 719] loss: 0.5285588273314142        